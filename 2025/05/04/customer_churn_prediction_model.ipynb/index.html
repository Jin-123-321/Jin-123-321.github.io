<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Customer Churn Prediction Model | Hexo</title><meta name="author" content="Jin"><meta name="copyright" content="Jin"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Telco Customer Churn Prediction1. 项目介绍 &amp; 目标说明“Predict behavior to retain customers. You can analyze all relevant customer data and develop focused customer retention programs.” [IBM Sample Data Se">
<meta property="og:type" content="article">
<meta property="og:title" content="Customer Churn Prediction Model">
<meta property="og:url" content="http://example.com/2025/05/04/customer_churn_prediction_model.ipynb/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="Telco Customer Churn Prediction1. 项目介绍 &amp; 目标说明“Predict behavior to retain customers. You can analyze all relevant customer data and develop focused customer retention programs.” [IBM Sample Data Se">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/img/avatar.png">
<meta property="article:published_time" content="2025-05-04T13:00:00.000Z">
<meta property="article:modified_time" content="2025-05-04T07:46:10.241Z">
<meta property="article:author" content="Jin">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="数据分析">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/avatar.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Customer Churn Prediction Model",
  "url": "http://example.com/2025/05/04/customer_churn_prediction_model.ipynb/",
  "image": "http://example.com/img/avatar.png",
  "datePublished": "2025-05-04T13:00:00.000Z",
  "dateModified": "2025-05-04T07:46:10.241Z",
  "author": [
    {
      "@type": "Person",
      "name": "Jin",
      "url": "http://example.com/"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2025/05/04/customer_churn_prediction_model.ipynb/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Failed',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Customer Churn Prediction Model',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">Hexo</span></a><a class="nav-page-title" href="/"><span class="site-name">Customer Churn Prediction Model</span></a></span><div id="menus"></div></nav><div id="post-info"><h1 class="post-title">Customer Churn Prediction Model</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2025-05-04T13:00:00.000Z" title="Created 2025-05-04 21:00:00">2025-05-04</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2025-05-04T07:46:10.241Z" title="Updated 2025-05-04 15:46:10">2025-05-04</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1 id="Telco-Customer-Churn-Prediction"><a href="#Telco-Customer-Churn-Prediction" class="headerlink" title="Telco Customer Churn Prediction"></a>Telco Customer Churn Prediction</h1><h2 id="1-项目介绍-目标说明"><a href="#1-项目介绍-目标说明" class="headerlink" title="1. 项目介绍 &amp; 目标说明"></a>1. 项目介绍 &amp; 目标说明</h2><p>“Predict behavior to retain customers. You can analyze all relevant customer data and develop focused customer retention programs.” [IBM Sample Data Sets]</p>
<p><a target="_blank" rel="noopener" href="https://www.kaggle.com/datasets/blastchar/telco-customer-churn?resource=download">https://www.kaggle.com/datasets/blastchar/telco-customer-churn?resource=download</a></p>
<h2 id="2-导入库-加载数据"><a href="#2-导入库-加载数据" class="headerlink" title="2. 导入库 &amp; 加载数据"></a>2. 导入库 &amp; 加载数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 导入库 &amp; 加载数据</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder, StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report, confusion_matrix, roc_auc_score</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置图表中文显示</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.family&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]      <span class="comment"># 支持中文字体</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>    <span class="comment"># 正常显示负号</span></span><br><span class="line">sns.<span class="built_in">set</span>(style=<span class="string">&quot;whitegrid&quot;</span>)                    <span class="comment"># 统一风格</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取数据</span></span><br><span class="line">df = pd.read_csv(<span class="string">&quot;telco_churn.csv&quot;</span>)</span><br><span class="line">df.head()</span><br><span class="line"></span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>customerID</th>
      <th>gender</th>
      <th>SeniorCitizen</th>
      <th>Partner</th>
      <th>Dependents</th>
      <th>tenure</th>
      <th>PhoneService</th>
      <th>MultipleLines</th>
      <th>InternetService</th>
      <th>OnlineSecurity</th>
      <th>...</th>
      <th>DeviceProtection</th>
      <th>TechSupport</th>
      <th>StreamingTV</th>
      <th>StreamingMovies</th>
      <th>Contract</th>
      <th>PaperlessBilling</th>
      <th>PaymentMethod</th>
      <th>MonthlyCharges</th>
      <th>TotalCharges</th>
      <th>Churn</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>7590-VHVEG</td>
      <td>Female</td>
      <td>0</td>
      <td>Yes</td>
      <td>No</td>
      <td>1</td>
      <td>No</td>
      <td>No phone service</td>
      <td>DSL</td>
      <td>No</td>
      <td>...</td>
      <td>No</td>
      <td>No</td>
      <td>No</td>
      <td>No</td>
      <td>Month-to-month</td>
      <td>Yes</td>
      <td>Electronic check</td>
      <td>29.85</td>
      <td>29.85</td>
      <td>No</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5575-GNVDE</td>
      <td>Male</td>
      <td>0</td>
      <td>No</td>
      <td>No</td>
      <td>34</td>
      <td>Yes</td>
      <td>No</td>
      <td>DSL</td>
      <td>Yes</td>
      <td>...</td>
      <td>Yes</td>
      <td>No</td>
      <td>No</td>
      <td>No</td>
      <td>One year</td>
      <td>No</td>
      <td>Mailed check</td>
      <td>56.95</td>
      <td>1889.5</td>
      <td>No</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3668-QPYBK</td>
      <td>Male</td>
      <td>0</td>
      <td>No</td>
      <td>No</td>
      <td>2</td>
      <td>Yes</td>
      <td>No</td>
      <td>DSL</td>
      <td>Yes</td>
      <td>...</td>
      <td>No</td>
      <td>No</td>
      <td>No</td>
      <td>No</td>
      <td>Month-to-month</td>
      <td>Yes</td>
      <td>Mailed check</td>
      <td>53.85</td>
      <td>108.15</td>
      <td>Yes</td>
    </tr>
    <tr>
      <th>3</th>
      <td>7795-CFOCW</td>
      <td>Male</td>
      <td>0</td>
      <td>No</td>
      <td>No</td>
      <td>45</td>
      <td>No</td>
      <td>No phone service</td>
      <td>DSL</td>
      <td>Yes</td>
      <td>...</td>
      <td>Yes</td>
      <td>Yes</td>
      <td>No</td>
      <td>No</td>
      <td>One year</td>
      <td>No</td>
      <td>Bank transfer (automatic)</td>
      <td>42.30</td>
      <td>1840.75</td>
      <td>No</td>
    </tr>
    <tr>
      <th>4</th>
      <td>9237-HQITU</td>
      <td>Female</td>
      <td>0</td>
      <td>No</td>
      <td>No</td>
      <td>2</td>
      <td>Yes</td>
      <td>No</td>
      <td>Fiber optic</td>
      <td>No</td>
      <td>...</td>
      <td>No</td>
      <td>No</td>
      <td>No</td>
      <td>No</td>
      <td>Month-to-month</td>
      <td>Yes</td>
      <td>Electronic check</td>
      <td>70.70</td>
      <td>151.65</td>
      <td>Yes</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 21 columns</p>
</div>



<h3 id="2-1-查看数据结构和数据类型"><a href="#2-1-查看数据结构和数据类型" class="headerlink" title="2.1. 查看数据结构和数据类型"></a>2.1. 查看数据结构和数据类型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看数据基本信息</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;📌 Data dimensions (rows, columns)：&quot;</span>, df.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n📌 Data types and non-null numbers:&quot;</span>)</span><br><span class="line">display(df.info())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看所有字段的唯一值数量（识别类别变量 vs 数值变量）</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n📌 Number of unique values ​​per column:&quot;</span>)</span><br><span class="line">display(df.nunique())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查缺失值</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n📌 Missing value statistics:&quot;</span>)</span><br><span class="line">display(df.isnull().<span class="built_in">sum</span>())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预览前几行</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n📌 Preview of the first five rows of data:&quot;</span>)</span><br><span class="line">display(df.head())</span><br></pre></td></tr></table></figure>

<pre><code>📌 Data dimensions (rows, columns)： (7043, 21)

📌 Data types and non-null numbers:
&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 7043 entries, 0 to 7042
Data columns (total 21 columns):
 #   Column            Non-Null Count  Dtype  
---  ------            --------------  -----  
 0   customerID        7043 non-null   object 
 1   gender            7043 non-null   object 
 2   SeniorCitizen     7043 non-null   int64  
 3   Partner           7043 non-null   object 
 4   Dependents        7043 non-null   object 
 5   tenure            7043 non-null   int64  
 6   PhoneService      7043 non-null   object 
 7   MultipleLines     7043 non-null   object 
 8   InternetService   7043 non-null   object 
 9   OnlineSecurity    7043 non-null   object 
 10  OnlineBackup      7043 non-null   object 
 11  DeviceProtection  7043 non-null   object 
 12  TechSupport       7043 non-null   object 
 13  StreamingTV       7043 non-null   object 
 14  StreamingMovies   7043 non-null   object 
 15  Contract          7043 non-null   object 
 16  PaperlessBilling  7043 non-null   object 
 17  PaymentMethod     7043 non-null   object 
 18  MonthlyCharges    7043 non-null   float64
 19  TotalCharges      7043 non-null   object 
 20  Churn             7043 non-null   object 
dtypes: float64(1), int64(2), object(18)
memory usage: 1.1+ MB



None
</code></pre>
<p>​<br>    📌 Number of unique values ​​per column:</p>
<pre><code>customerID          7043
gender                 2
SeniorCitizen          2
Partner                2
Dependents             2
tenure                73
PhoneService           2
MultipleLines          3
InternetService        3
OnlineSecurity         3
OnlineBackup           3
DeviceProtection       3
TechSupport            3
StreamingTV            3
StreamingMovies        3
Contract               3
PaperlessBilling       2
PaymentMethod          4
MonthlyCharges      1585
TotalCharges        6531
Churn                  2
dtype: int64
</code></pre>
<p>​<br>    📌 Missing value statistics:</p>
<pre><code>customerID          0
gender              0
SeniorCitizen       0
Partner             0
Dependents          0
tenure              0
PhoneService        0
MultipleLines       0
InternetService     0
OnlineSecurity      0
OnlineBackup        0
DeviceProtection    0
TechSupport         0
StreamingTV         0
StreamingMovies     0
Contract            0
PaperlessBilling    0
PaymentMethod       0
MonthlyCharges      0
TotalCharges        0
Churn               0
dtype: int64
</code></pre>
<p>​<br>    📌 Preview of the first five rows of data:</p>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>customerID</th>
      <th>gender</th>
      <th>SeniorCitizen</th>
      <th>Partner</th>
      <th>Dependents</th>
      <th>tenure</th>
      <th>PhoneService</th>
      <th>MultipleLines</th>
      <th>InternetService</th>
      <th>OnlineSecurity</th>
      <th>...</th>
      <th>DeviceProtection</th>
      <th>TechSupport</th>
      <th>StreamingTV</th>
      <th>StreamingMovies</th>
      <th>Contract</th>
      <th>PaperlessBilling</th>
      <th>PaymentMethod</th>
      <th>MonthlyCharges</th>
      <th>TotalCharges</th>
      <th>Churn</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>7590-VHVEG</td>
      <td>Female</td>
      <td>0</td>
      <td>Yes</td>
      <td>No</td>
      <td>1</td>
      <td>No</td>
      <td>No phone service</td>
      <td>DSL</td>
      <td>No</td>
      <td>...</td>
      <td>No</td>
      <td>No</td>
      <td>No</td>
      <td>No</td>
      <td>Month-to-month</td>
      <td>Yes</td>
      <td>Electronic check</td>
      <td>29.85</td>
      <td>29.85</td>
      <td>No</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5575-GNVDE</td>
      <td>Male</td>
      <td>0</td>
      <td>No</td>
      <td>No</td>
      <td>34</td>
      <td>Yes</td>
      <td>No</td>
      <td>DSL</td>
      <td>Yes</td>
      <td>...</td>
      <td>Yes</td>
      <td>No</td>
      <td>No</td>
      <td>No</td>
      <td>One year</td>
      <td>No</td>
      <td>Mailed check</td>
      <td>56.95</td>
      <td>1889.5</td>
      <td>No</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3668-QPYBK</td>
      <td>Male</td>
      <td>0</td>
      <td>No</td>
      <td>No</td>
      <td>2</td>
      <td>Yes</td>
      <td>No</td>
      <td>DSL</td>
      <td>Yes</td>
      <td>...</td>
      <td>No</td>
      <td>No</td>
      <td>No</td>
      <td>No</td>
      <td>Month-to-month</td>
      <td>Yes</td>
      <td>Mailed check</td>
      <td>53.85</td>
      <td>108.15</td>
      <td>Yes</td>
    </tr>
    <tr>
      <th>3</th>
      <td>7795-CFOCW</td>
      <td>Male</td>
      <td>0</td>
      <td>No</td>
      <td>No</td>
      <td>45</td>
      <td>No</td>
      <td>No phone service</td>
      <td>DSL</td>
      <td>Yes</td>
      <td>...</td>
      <td>Yes</td>
      <td>Yes</td>
      <td>No</td>
      <td>No</td>
      <td>One year</td>
      <td>No</td>
      <td>Bank transfer (automatic)</td>
      <td>42.30</td>
      <td>1840.75</td>
      <td>No</td>
    </tr>
    <tr>
      <th>4</th>
      <td>9237-HQITU</td>
      <td>Female</td>
      <td>0</td>
      <td>No</td>
      <td>No</td>
      <td>2</td>
      <td>Yes</td>
      <td>No</td>
      <td>Fiber optic</td>
      <td>No</td>
      <td>...</td>
      <td>No</td>
      <td>No</td>
      <td>No</td>
      <td>No</td>
      <td>Month-to-month</td>
      <td>Yes</td>
      <td>Electronic check</td>
      <td>70.70</td>
      <td>151.65</td>
      <td>Yes</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 21 columns</p>
</div>


<h4 id="🧼-数据清洗重点总结"><a href="#🧼-数据清洗重点总结" class="headerlink" title="🧼 数据清洗重点总结"></a>🧼 数据清洗重点总结</h4><p>根据数据加载与描述性统计结果，当前数据存在以下需要清洗的关键点：</p>
<table>
<thead>
<tr>
<th>字段名</th>
<th>问题描述</th>
<th>建议处理方式</th>
</tr>
</thead>
<tbody><tr>
<td><code>customerID</code></td>
<td>标识符</td>
<td>删</td>
</tr>
<tr>
<td><code>TotalCharges</code></td>
<td>被识别为 object 类型，实为数值型</td>
<td>转换为 float，并处理缺失值</td>
</tr>
<tr>
<td>多个服务字段（如 <code>OnlineSecurity</code>, <code>StreamingTV</code>, <code>MultipleLines</code> 等）</td>
<td>部分类别值为 <code>&quot;No internet service&quot;</code> 或 <code>&quot;No phone service&quot;</code>，实际上等同于 <code>&quot;No&quot;</code></td>
<td>将这些特殊类别统一归为 <code>&quot;No&quot;</code></td>
</tr>
<tr>
<td><code>SeniorCitizen</code></td>
<td>数据类型为 int64（0&#x2F;1），本质上是类别变量</td>
<td>保留 or 转换为字符串类别再进行编码</td>
</tr>
<tr>
<td><code>Churn</code></td>
<td>目标变量为 “Yes”&#x2F;“No”，为 object 类型</td>
<td>映射为二元数值变量</td>
</tr>
<tr>
<td>其他类别变量（如 <code>gender</code>, <code>Contract</code>, <code>PaymentMethod</code> 等）</td>
<td>为 object 类型，需进行编码处理</td>
<td>LabelEncoder 或 OneHotEncoder</td>
</tr>
</tbody></table>
<hr>
<h5 id="✅-清洗完成后的目标："><a href="#✅-清洗完成后的目标：" class="headerlink" title="✅ 清洗完成后的目标："></a>✅ 清洗完成后的目标：</h5><ul>
<li>所有特征数据类型明确（数值型 or 编码后的类别型）</li>
<li>无缺失值或已妥善填补&#x2F;删除</li>
<li>目标变量 <code>Churn</code> 为 0&#x2F;1 数值型</li>
<li>删除无用字段（如 <code>customerID</code>）</li>
</ul>
<h2 id="3-数据清洗与预处理"><a href="#3-数据清洗与预处理" class="headerlink" title="3. 数据清洗与预处理"></a>3. 数据清洗与预处理</h2><h3 id="3-1-缺失值处理"><a href="#3-1-缺失值处理" class="headerlink" title="3.1 缺失值处理"></a>3.1 缺失值处理</h3><p>在本步骤中，我们主要处理 <code>TotalCharges</code> 字段中的异常值（空字符串导致的转换失败），并删除无法转换为数值的 11 条记录。</p>
<hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将 TotalCharges 从 object 转为 float，错误的设为 NaN</span></span><br><span class="line">df[<span class="string">&#x27;TotalCharges&#x27;</span>] = pd.to_numeric(df[<span class="string">&#x27;TotalCharges&#x27;</span>], errors=<span class="string">&#x27;coerce&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看转换失败数量（即 NaN）</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;❗ TotalCharges Number of conversion failures (NaN):&quot;</span>, df[<span class="string">&#x27;TotalCharges&#x27;</span>].isnull().<span class="built_in">sum</span>())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除包含 NaN 的记录（共 11 条）</span></span><br><span class="line">df.dropna(subset=[<span class="string">&#x27;TotalCharges&#x27;</span>], inplace=<span class="literal">True</span>)</span><br><span class="line">df.reset_index(drop=<span class="literal">True</span>, inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 缺失值处理后查看总览</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;✅ The data structure after missing value processing is completed:&quot;</span>)</span><br><span class="line">display(df.info())</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>❗ TotalCharges Number of conversion failures (NaN): 11
✅ The data structure after missing value processing is completed:
&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 7032 entries, 0 to 7031
Data columns (total 21 columns):
 #   Column            Non-Null Count  Dtype  
---  ------            --------------  -----  
 0   customerID        7032 non-null   object 
 1   gender            7032 non-null   object 
 2   SeniorCitizen     7032 non-null   int64  
 3   Partner           7032 non-null   object 
 4   Dependents        7032 non-null   object 
 5   tenure            7032 non-null   int64  
 6   PhoneService      7032 non-null   object 
 7   MultipleLines     7032 non-null   object 
 8   InternetService   7032 non-null   object 
 9   OnlineSecurity    7032 non-null   object 
 10  OnlineBackup      7032 non-null   object 
 11  DeviceProtection  7032 non-null   object 
 12  TechSupport       7032 non-null   object 
 13  StreamingTV       7032 non-null   object 
 14  StreamingMovies   7032 non-null   object 
 15  Contract          7032 non-null   object 
 16  PaperlessBilling  7032 non-null   object 
 17  PaymentMethod     7032 non-null   object 
 18  MonthlyCharges    7032 non-null   float64
 19  TotalCharges      7032 non-null   float64
 20  Churn             7032 non-null   object 
dtypes: float64(2), int64(2), object(17)
memory usage: 1.1+ MB



None
</code></pre>
<h3 id="3-2-特征编码"><a href="#3-2-特征编码" class="headerlink" title="3.2 特征编码"></a>3.2 特征编码</h3><p>我们将以下字段中的类别值 <code>&quot;No internet service&quot;</code> &#x2F; <code>&quot;No phone service&quot;</code> 统一替换为 <code>&quot;No&quot;</code>，并使用 LabelEncoder 对所有类别型变量进行编码。</p>
<hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 替换 &quot;No internet service&quot; / &quot;No phone service&quot; 为 &quot;No&quot;</span></span><br><span class="line">replace_cols = [<span class="string">&#x27;MultipleLines&#x27;</span>, <span class="string">&#x27;OnlineSecurity&#x27;</span>, <span class="string">&#x27;OnlineBackup&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;DeviceProtection&#x27;</span>, <span class="string">&#x27;TechSupport&#x27;</span>, <span class="string">&#x27;StreamingTV&#x27;</span>, <span class="string">&#x27;StreamingMovies&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> replace_cols:</span><br><span class="line">    df[col] = df[col].replace(&#123;<span class="string">&#x27;No internet service&#x27;</span>: <span class="string">&#x27;No&#x27;</span>, <span class="string">&#x27;No phone service&#x27;</span>: <span class="string">&#x27;No&#x27;</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将目标变量 Churn 映射为数值型</span></span><br><span class="line">df[<span class="string">&#x27;Churn&#x27;</span>] = df[<span class="string">&#x27;Churn&#x27;</span>].<span class="built_in">map</span>(&#123;<span class="string">&#x27;No&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;Yes&#x27;</span>: <span class="number">1</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对所有 object 类型字段进行 Label Encoding</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line">label_cols = df.select_dtypes(include=<span class="string">&#x27;object&#x27;</span>).columns.tolist()</span><br><span class="line"></span><br><span class="line">le = LabelEncoder()</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> label_cols:</span><br><span class="line">    df[col] = le.fit_transform(df[col])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看编码后数据类型</span></span><br><span class="line">df.dtypes</span><br><span class="line"></span><br></pre></td></tr></table></figure>




<pre><code>customerID            int64
gender                int64
SeniorCitizen         int64
Partner               int64
Dependents            int64
tenure                int64
PhoneService          int64
MultipleLines         int64
InternetService       int64
OnlineSecurity        int64
OnlineBackup          int64
DeviceProtection      int64
TechSupport           int64
StreamingTV           int64
StreamingMovies       int64
Contract              int64
PaperlessBilling      int64
PaymentMethod         int64
MonthlyCharges      float64
TotalCharges        float64
Churn                 int64
dtype: object
</code></pre>
<p>⚠️ 注意：本项目使用 Pipeline 对模型进行封装，因此我们不在此阶段直接执行数值特征的缩放操作。</p>
<p>我们将在后续的模型训练中，通过 <code>ColumnTransformer + StandardScaler</code> 统一管理数值特征的缩放，以确保不同模型使用各自对应的预处理方式。</p>
<h3 id="3-3-特征缩放"><a href="#3-3-特征缩放" class="headerlink" title="3.3 特征缩放"></a>3.3 特征缩放</h3><p>⚠️ 注意：原本准备使用Pipeline 对模型进行封装，因此我们不在此阶段直接执行数值特征的缩放操作，但考虑到顾客流失原因分析。对模型解释SHAP非常重要。</p>
<p>因此我们降维每个模型设置合适的缩放器管理，分开保存</p>
<table>
<thead>
<tr>
<th>模型</th>
<th>推荐缩放方法</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>Logistic Regression&#x2F; SVM</td>
<td>StandardScaler</td>
<td>梯度下降对特征尺度敏感</td>
</tr>
<tr>
<td>KNN</td>
<td>MinMaxScaler</td>
<td>距离计算敏感，需要归一化</td>
</tr>
<tr>
<td>Neural Network</td>
<td>MinMax 或 Standard</td>
<td>有助于快速收敛</td>
</tr>
<tr>
<td>Random Forest &#x2F; XGBoost</td>
<td>无需缩放</td>
<td>基于树分裂，数值大小无影响</td>
</tr>
</tbody></table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler, MinMaxScaler</span><br><span class="line"></span><br><span class="line"><span class="comment"># 拆分特征和标签</span></span><br><span class="line">X = df.drop(<span class="string">&#x27;Churn&#x27;</span>, axis=<span class="number">1</span>)</span><br><span class="line">y = df[<span class="string">&#x27;Churn&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 拆分训练和测试集（Stratify 保证标签平衡）</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(</span><br><span class="line">    X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>, stratify=y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义数值列（需要缩放）</span></span><br><span class="line">num_cols = [<span class="string">&#x27;MonthlyCharges&#x27;</span>, <span class="string">&#x27;TotalCharges&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Logistic / SVM 使用 StandardScaler</span></span><br><span class="line">std_scaler = StandardScaler()</span><br><span class="line">X_train_std = X_train.copy()</span><br><span class="line">X_test_std = X_test.copy()</span><br><span class="line">X_train_std[num_cols] = std_scaler.fit_transform(X_train[num_cols])</span><br><span class="line">X_test_std[num_cols] = std_scaler.transform(X_test[num_cols])</span><br><span class="line"></span><br><span class="line"><span class="comment"># KNN / MLP 使用 MinMaxScaler</span></span><br><span class="line">mm_scaler = MinMaxScaler()</span><br><span class="line">X_train_mm = X_train.copy()</span><br><span class="line">X_test_mm = X_test.copy()</span><br><span class="line">X_train_mm[num_cols] = mm_scaler.fit_transform(X_train[num_cols])</span><br><span class="line">X_test_mm[num_cols] = mm_scaler.transform(X_test[num_cols])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Random Forest / XGBoost 使用原始数据（不缩放）</span></span><br><span class="line">X_train_raw = X_train.copy()</span><br><span class="line">X_test_raw = X_test.copy()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="4-探索性数据分析（EDA）"><a href="#4-探索性数据分析（EDA）" class="headerlink" title="4. 探索性数据分析（EDA）"></a>4. 探索性数据分析（EDA）</h2><h3 id="4-1-目标变量分布（Churn-概况）"><a href="#4-1-目标变量分布（Churn-概况）" class="headerlink" title="4.1 目标变量分布（Churn 概况）"></a>4.1 目标变量分布（Churn 概况）</h3><p>首先查看目标变量 <code>Churn</code> 的总体分布，判断是否存在类别不平衡问题，以便后续考虑是否需要过采样&#x2F;欠采样或加权。</p>
<hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置主题</span></span><br><span class="line">sns.<span class="built_in">set</span>(style=<span class="string">&quot;whitegrid&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 画 Churn 分布柱状图</span></span><br><span class="line">plt.figure(figsize=(<span class="number">6</span>, <span class="number">4</span>))</span><br><span class="line">sns.countplot(x=<span class="string">&#x27;Churn&#x27;</span>, data=df, palette=<span class="string">&#x27;Set2&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Customer churn distribution (0 = no churn, 1 = churn)&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Whether it is lost&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Number of customers&quot;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出流失比例</span></span><br><span class="line">churn_rate = df[<span class="string">&#x27;Churn&#x27;</span>].value_counts(normalize=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;📊 Churn rate（Churn=1）:&quot;</span>, <span class="built_in">round</span>(churn_rate[<span class="number">1</span>]*<span class="number">100</span>, <span class="number">2</span>), <span class="string">&quot;%&quot;</span>)</span><br></pre></td></tr></table></figure>


<p>​<br><img src="/2025/05/04/customer_churn_prediction_model/customer_churn_prediction_model.ipynb_23_0.png" alt="png"><br>​    </p>
<pre><code>📊 Churn rate（Churn=1）: 26.58 %
</code></pre>
<h4 id="⚖️-类别不平衡处理方法说明"><a href="#⚖️-类别不平衡处理方法说明" class="headerlink" title="⚖️ 类别不平衡处理方法说明"></a>⚖️ 类别不平衡处理方法说明</h4><p>在 Telco 数据集中，客户流失（Churn&#x3D;1）仅占约 26%，存在明显类别不平衡。</p>
<p>为了解决模型可能忽视少数类（流失客户）的风险，我们可以考虑以下策略：</p>
<ul>
<li><strong>过采样（Oversampling）</strong>：增加少数类样本</li>
<li><strong>欠采样（Undersampling）</strong>：减少多数类样本</li>
<li><strong>类别加权（Class Weighting）</strong>：对少数类施加更高训练权重（推荐）</li>
</ul>
<p>本项目后续在建模中将采用 <code>class_weight=&#39;balanced&#39;</code> 参数，提高模型对流失客户的识别能力。</p>
<h3 id="4-2-👨‍👩‍👧-类别变量-vs-流失率（单变量分析）"><a href="#4-2-👨‍👩‍👧-类别变量-vs-流失率（单变量分析）" class="headerlink" title="4.2 👨‍👩‍👧 类别变量 vs. 流失率（单变量分析）"></a>4.2 👨‍👩‍👧 类别变量 vs. 流失率（单变量分析）</h3><p>我们分析每个类别变量下的流失率，帮助我们判断哪些特征与流失高度相关。重点考察：</p>
<ul>
<li><code>gender</code></li>
<li><code>SeniorCitizen</code></li>
<li><code>Partner</code></li>
<li><code>Contract</code></li>
<li><code>InternetService</code></li>
<li><code>PaymentMethod</code></li>
</ul>
<hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义你想分析的类别变量</span></span><br><span class="line">cat_vars = [<span class="string">&#x27;gender&#x27;</span>, <span class="string">&#x27;SeniorCitizen&#x27;</span>, <span class="string">&#x27;Partner&#x27;</span>, <span class="string">&#x27;Dependents&#x27;</span>, </span><br><span class="line">            <span class="string">&#x27;PhoneService&#x27;</span>, <span class="string">&#x27;MultipleLines&#x27;</span>, <span class="string">&#x27;InternetService&#x27;</span>, </span><br><span class="line">            <span class="string">&#x27;OnlineSecurity&#x27;</span>, <span class="string">&#x27;Contract&#x27;</span>, <span class="string">&#x27;PaymentMethod&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化每个类别变量下的流失率</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">18</span>, <span class="number">15</span>))</span><br><span class="line"><span class="keyword">for</span> i, var <span class="keyword">in</span> <span class="built_in">enumerate</span>(cat_vars):</span><br><span class="line">    plt.subplot(<span class="number">4</span>, <span class="number">3</span>, i+<span class="number">1</span>)</span><br><span class="line">    sns.barplot(x=var, y=<span class="string">&#x27;Churn&#x27;</span>, data=df, ci=<span class="literal">None</span>, palette=<span class="string">&#x27;Set3&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">f&quot;<span class="subst">&#123;var&#125;</span> vs. Churn&quot;</span>)</span><br><span class="line">    plt.xticks(rotation=<span class="number">45</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p>​<br><img src="/2025/05/04/customer_churn_prediction_model/customer_churn_prediction_model.ipynb_27_0.png" alt="png"><br>​    </p>
<p>类别变量 vs. 流失率分析（结果解读）</p>
<p>以下是各类别变量在不同取值下的客户流失率（Churn&#x3D;1）柱状图，我们可以从中发现一些明显的规律：</p>
<ul>
<li><p><strong>Contract（合同类型）</strong>：影响最大。选择 <strong>Month-to-month（月度合同）</strong> 的客户流失率明显高于一年&#x2F;两年合约客户，说明<strong>长期合同有助于降低流失率</strong>。</p>
</li>
<li><p><strong>PaymentMethod（支付方式）</strong>：使用 <strong>Electronic check（电子支票）</strong> 的客户流失率最高，可能意味着这类用户付款方式灵活、稳定性差。</p>
</li>
<li><p><strong>OnlineSecurity &#x2F; TechSupport &#x2F; InternetService</strong>：没有这些服务（或未订阅网络服务）的客户，流失率普遍较高，说明<strong>基础服务与附加保障功能可能提高用户黏性</strong>。</p>
</li>
<li><p><strong>Partner &#x2F; Dependents（是否有配偶或子女）</strong>：有家庭责任的客户流失率更低，可能体现了这类用户对服务的依赖性更高。</p>
</li>
<li><p><strong>SeniorCitizen &#x2F; PhoneService &#x2F; MultipleLines &#x2F; gender</strong>：这些变量的影响相对较弱，性别几乎不影响流失行为；是否为老年人略有差异但不显著。</p>
</li>
</ul>
<p>这些发现为我们后续特征选择和模型训练提供了有价值的依据，特别是：</p>
<ul>
<li><code>Contract</code>, <code>PaymentMethod</code>, <code>OnlineSecurity</code>, <code>InternetService</code> 等变量应重点关注；</li>
<li><code>gender</code>, <code>PhoneService</code> 可作为次要变量处理。</li>
</ul>
<h3 id="4-3-📉-数值变量在不同流失状态下的分布（箱线图分析）"><a href="#4-3-📉-数值变量在不同流失状态下的分布（箱线图分析）" class="headerlink" title="4.3 📉 数值变量在不同流失状态下的分布（箱线图分析）"></a>4.3 📉 数值变量在不同流失状态下的分布（箱线图分析）</h3><p>我们使用箱线图对数值变量进行分组可视化，观察不同流失状态下的客户在 <code>tenure</code>, <code>MonthlyCharges</code>, <code>TotalCharges</code> 三个关键指标上的分布差异。</p>
<p>箱线图可以帮助我们识别：</p>
<ul>
<li>均值&#x2F;中位数是否有显著差异；</li>
<li>是否存在极端值；</li>
<li>哪些特征能更好地区分流失与否。</li>
</ul>
<hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">18</span>, <span class="number">5</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># tenure vs. Churn</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">sns.boxplot(x=<span class="string">&#x27;Churn&#x27;</span>, y=<span class="string">&#x27;tenure&#x27;</span>, data=df, palette=<span class="string">&#x27;Set2&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Tenure vs. Churn&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Whether it is lost&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Months online（tenure）&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># MonthlyCharges vs. Churn</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">sns.boxplot(x=<span class="string">&#x27;Churn&#x27;</span>, y=<span class="string">&#x27;MonthlyCharges&#x27;</span>, data=df, palette=<span class="string">&#x27;Set3&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;MonthlyCharges vs. Churn&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Whether it is lost&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Monthly Fees&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># TotalCharges vs. Churn</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">sns.boxplot(x=<span class="string">&#x27;Churn&#x27;</span>, y=<span class="string">&#x27;TotalCharges&#x27;</span>, data=df, palette=<span class="string">&#x27;Set1&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;TotalCharges vs. Churn&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Whether it is lost&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Total cost&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p>​<br><img src="/2025/05/04/customer_churn_prediction_model/customer_churn_prediction_model.ipynb_31_0.png" alt="png"><br>​    </p>
<h5 id="✅-tenure（在网时长）"><a href="#✅-tenure（在网时长）" class="headerlink" title="✅ tenure（在网时长）"></a>✅ tenure（在网时长）</h5><ul>
<li><strong>未流失用户（Churn&#x3D;0）</strong>：中位数在约 45 个月，整体分布集中在 20～70 个月。</li>
<li><strong>流失用户（Churn&#x3D;1）</strong>：中位数明显较低，仅约 10 个月，大量集中在前 1～20 月。</li>
</ul>
<p>👉 <strong>解读</strong>：新用户更容易流失，客户在网时间越长，流失可能性越低。这说明忠诚客户留存效果显著。</p>
<hr>
<h5 id="✅-MonthlyCharges（月度收费）"><a href="#✅-MonthlyCharges（月度收费）" class="headerlink" title="✅ MonthlyCharges（月度收费）"></a>✅ MonthlyCharges（月度收费）</h5><ul>
<li><strong>流失用户</strong>的月度费用 <strong>中位数更高</strong>，分布偏右（较大值更多）。</li>
<li><strong>未流失用户</strong>月消费分布更广，低费用用户更多。</li>
</ul>
<p>👉 <strong>解读</strong>：高月消费客户可能对价格更敏感，或者使用了更多服务，因此流失率偏高。应考虑是否提供长期合同或优惠策略来降低这类用户的流失。</p>
<hr>
<h5 id="✅-TotalCharges（总费用）"><a href="#✅-TotalCharges（总费用）" class="headerlink" title="✅ TotalCharges（总费用）"></a>✅ TotalCharges（总费用）</h5><ul>
<li><strong>未流失用户</strong>的总费用分布更宽，最高达 8600+，中位数约为 2300。</li>
<li><strong>流失用户</strong>中位数很低，约为 400，且出现多个异常值（上方小圆点）。</li>
</ul>
<p>👉 <strong>解读</strong>：TotalCharges 本质受 tenure 影响较大。流失用户因为在网时间短，总费用偏低。此特征与 tenure 有一定相关性，但依然具有区分能力。</p>
<hr>
<h4 id="🔍-小结建议"><a href="#🔍-小结建议" class="headerlink" title="🔍 小结建议"></a>🔍 小结建议</h4><ul>
<li><strong>tenure</strong> 是影响流失最明显的变量，模型应重点考虑；</li>
<li><strong>MonthlyCharges</strong> 与客户满意度&#x2F;价格敏感度相关，也需重点引入；</li>
<li><strong>TotalCharges</strong> 虽然与 tenure 高相关，但仍能提供价值，建议保留。</li>
</ul>
<p>后续可以进一步通过相关性热力图确认变量之间是否存在多重共线。</p>
<h3 id="4-4-🔥-特征相关性热力图"><a href="#4-4-🔥-特征相关性热力图" class="headerlink" title="4.4 🔥 特征相关性热力图"></a>4.4 🔥 特征相关性热力图</h3><p>我们使用 <code>df.corr()</code> 计算变量之间的 Pearson 相关系数，并通过热力图可视化各特征之间的线性相关性。</p>
<ul>
<li>深色代表相关性强（正&#x2F;负）</li>
<li><code>Churn</code> 与其他变量的相关性可以揭示哪些特征是潜在的预测因子</li>
<li>若两个输入特征高度相关，可能需要考虑降维或去除其中之一（避免共线性）</li>
</ul>
<hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">14</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算相关系数矩阵</span></span><br><span class="line">corr_matrix = df.corr()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 画热力图</span></span><br><span class="line">sns.heatmap(corr_matrix, annot=<span class="literal">True</span>, fmt=<span class="string">&quot;.2f&quot;</span>, cmap=<span class="string">&#x27;coolwarm&#x27;</span>, center=<span class="number">0</span>,</span><br><span class="line">            linewidths=<span class="number">0.5</span>, linecolor=<span class="string">&#x27;gray&#x27;</span>, square=<span class="literal">True</span>, cbar_kws=&#123;<span class="string">&quot;shrink&quot;</span>: <span class="number">.6</span>&#125;)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&quot;📊 Feature Correlation Heatmap（Pearson）&quot;</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">plt.xticks(rotation=<span class="number">45</span>)</span><br><span class="line">plt.yticks(rotation=<span class="number">0</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p>​<br><img src="/2025/05/04/customer_churn_prediction_model/customer_churn_prediction_model.ipynb_35_0.png" alt="png"><br>​    </p>
<h5 id="✅-与目标变量-Churn-的相关性"><a href="#✅-与目标变量-Churn-的相关性" class="headerlink" title="✅ 与目标变量 Churn 的相关性"></a>✅ 与目标变量 <code>Churn</code> 的相关性</h5><ul>
<li><p><strong>tenure</strong> 与 Churn 的相关性最强（-0.35），为负相关<br>👉 在网时间越长，客户越不容易流失，符合业务直觉</p>
</li>
<li><p><strong>OnlineSecurity</strong>（-0.28）、<strong>TechSupport</strong>（-0.27）、<strong>Contract</strong>（-0.39）也呈负相关<br>👉 说明使用保障服务、签订长期合同的用户更稳定</p>
</li>
<li><p><strong>MonthlyCharges</strong>（+0.19）为少数正相关的数值变量<br>👉 消费越高的用户流失率略高，可能存在价格敏感问题</p>
</li>
</ul>
<hr>
<h5 id="⚠️-特征之间的强相关性（潜在冗余）"><a href="#⚠️-特征之间的强相关性（潜在冗余）" class="headerlink" title="⚠️ 特征之间的强相关性（潜在冗余）"></a>⚠️ 特征之间的强相关性（潜在冗余）</h5><ul>
<li><p><code>TotalCharges</code> 与 <code>tenure</code> 相关性高达 <strong>+0.83</strong><br>👉 可能存在信息重叠（TotalCharges &#x3D; MonthlyCharges × tenure 的近似函数），在使用线性模型时需注意共线性问题</p>
</li>
<li><p><code>OnlineSecurity</code>, <code>OnlineBackup</code>, <code>TechSupport</code> 彼此也存在中度相关（约 0.3~0.4）<br>👉 可视为“附加服务群”，也许后期可以考虑构造一个服务合成特征</p>
</li>
</ul>
<hr>
<h4 id="✅-建议（为后续建模做准备）"><a href="#✅-建议（为后续建模做准备）" class="headerlink" title="✅ 建议（为后续建模做准备）"></a>✅ 建议（为后续建模做准备）</h4><ul>
<li><strong>保留特征</strong>：<code>tenure</code>, <code>MonthlyCharges</code>, <code>Contract</code>, <code>OnlineSecurity</code>, <code>TechSupport</code> 是高价值变量，应重点关注</li>
<li><strong>需注意冗余</strong>：<code>TotalCharges</code> 与 <code>tenure</code> 可择一使用于线性模型中，或通过 PCA 降维</li>
<li><strong>不建议删除但影响较小的特征</strong>：如 <code>gender</code>, <code>PhoneService</code>, <code>DeviceProtection</code>，可以在后续模型中进行重要性评估</li>
</ul>
<h3 id="4-5-🎯-数值变量分布图（按流失情况分组）"><a href="#4-5-🎯-数值变量分布图（按流失情况分组）" class="headerlink" title="4.5 🎯 数值变量分布图（按流失情况分组）"></a>4.5 🎯 数值变量分布图（按流失情况分组）</h3><p>我们将目标变量 <code>Churn</code> 作为分组条件，分别绘制主要数值变量的分布图。</p>
<p>本节重点分析：</p>
<ul>
<li><code>tenure</code>：在网时长</li>
<li><code>MonthlyCharges</code>：月度消费金额</li>
<li><code>TotalCharges</code>：累计消费金额</li>
</ul>
<p>通过对比流失 vs 未流失人群在各变量上的分布差异，辅助判断变量的区分能力和潜在影响。</p>
<hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置风格</span></span><br><span class="line">sns.<span class="built_in">set</span>(style=<span class="string">&quot;whitegrid&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置图形区域</span></span><br><span class="line">plt.figure(figsize=(<span class="number">18</span>, <span class="number">5</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># tenure 分布</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">sns.kdeplot(data=df, x=<span class="string">&#x27;tenure&#x27;</span>, hue=<span class="string">&#x27;Churn&#x27;</span>, fill=<span class="literal">True</span>, common_norm=<span class="literal">False</span>, palette=<span class="string">&#x27;Set2&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;tenure distribution - grouped by churn&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># MonthlyCharges 分布</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">sns.kdeplot(data=df, x=<span class="string">&#x27;MonthlyCharges&#x27;</span>, hue=<span class="string">&#x27;Churn&#x27;</span>, fill=<span class="literal">True</span>, common_norm=<span class="literal">False</span>, palette=<span class="string">&#x27;Set1&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;MonthlyCharges distribution - grouped by churn&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># TotalCharges 分布</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">sns.kdeplot(data=df, x=<span class="string">&#x27;TotalCharges&#x27;</span>, hue=<span class="string">&#x27;Churn&#x27;</span>, fill=<span class="literal">True</span>, common_norm=<span class="literal">False</span>, palette=<span class="string">&#x27;Set3&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;TotalCharges distribution - grouped by churn&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p>​<br><img src="/2025/05/04/customer_churn_prediction_model/customer_churn_prediction_model.ipynb_39_0.png" alt="png"><br>​    </p>
<h5 id="1️⃣-tenure（在网时长）"><a href="#1️⃣-tenure（在网时长）" class="headerlink" title="1️⃣ tenure（在网时长）"></a>1️⃣ <code>tenure</code>（在网时长）</h5><ul>
<li><strong>流失用户（Churn&#x3D;1）</strong>：分布集中于左侧（低 tenure），在 0–15 月内出现密集峰值</li>
<li><strong>未流失用户（Churn&#x3D;0）</strong>：分布更加均匀，中长 tenure 客户比例较高</li>
</ul>
<p>📌 <strong>解读</strong>：说明新注册用户更容易流失，<code>tenure</code> 是非常关键的流失预测因子。</p>
<hr>
<h5 id="2️⃣-MonthlyCharges（月度消费）"><a href="#2️⃣-MonthlyCharges（月度消费）" class="headerlink" title="2️⃣ MonthlyCharges（月度消费）"></a>2️⃣ <code>MonthlyCharges</code>（月度消费）</h5><ul>
<li><strong>流失用户</strong>：分布更“偏右”，即高费用群体流失率较高</li>
<li><strong>未流失用户</strong>：在中低消费段（约 $20–70）较为集中</li>
</ul>
<p>📌 <strong>解读</strong>：高消费客户可能对服务质量或价格更敏感，因此需要更多保留策略（如打包优惠、长期合同等）。</p>
<hr>
<h5 id="3️⃣-TotalCharges（总消费金额）"><a href="#3️⃣-TotalCharges（总消费金额）" class="headerlink" title="3️⃣ TotalCharges（总消费金额）"></a>3️⃣ <code>TotalCharges</code>（总消费金额）</h5><ul>
<li><strong>流失用户</strong>：分布非常集中于低值区域（&lt; $2000），且右尾快速衰减</li>
<li><strong>未流失用户</strong>：分布更宽，尾部延展至 $8000 以上</li>
</ul>
<p>📌 <strong>解读</strong>：TotalCharges 在一定程度上受 <code>tenure</code> 控制，说明多数流失用户在网时间短、累计费用少。</p>
<hr>
<h4 id="✅-综合结论"><a href="#✅-综合结论" class="headerlink" title="✅ 综合结论"></a>✅ 综合结论</h4><ul>
<li><code>tenure</code> 是最具区分力的变量，对流失识别作用最明显</li>
<li><code>MonthlyCharges</code> 提供了独立于 tenure 的区分信息，尤其是对高消费人群</li>
<li><code>TotalCharges</code> 与 <code>tenure</code> 强相关，在非线性模型中仍可保留，在逻辑回归中建议与其他变量搭配使用</li>
</ul>
<h3 id="4-6-🔍-高阶组合特征交叉分析"><a href="#4-6-🔍-高阶组合特征交叉分析" class="headerlink" title="4.6 🔍 高阶组合特征交叉分析"></a>4.6 🔍 高阶组合特征交叉分析</h3><p>本节通过多个关键变量组合进行交叉分组，观察不同组合下的流失率变化，进一步刻画“流失风险用户画像”。</p>
<hr>
<h4 id="1️⃣-Contract-PaymentMethod-对流失率的影响"><a href="#1️⃣-Contract-PaymentMethod-对流失率的影响" class="headerlink" title="1️⃣ Contract + PaymentMethod 对流失率的影响"></a>1️⃣ Contract + PaymentMethod 对流失率的影响</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">6</span>))</span><br><span class="line">sns.barplot(data=df, x=<span class="string">&#x27;Contract&#x27;</span>, y=<span class="string">&#x27;Churn&#x27;</span>, hue=<span class="string">&#x27;PaymentMethod&#x27;</span>, palette=<span class="string">&#x27;Set2&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Contract + PaymentMethod Impact on churn rate&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Churn rate&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Contract Type&quot;</span>)</span><br><span class="line">plt.legend(title=<span class="string">&#x27;Payment Methods&#x27;</span>, bbox_to_anchor=(<span class="number">1.05</span>, <span class="number">1</span>), loc=<span class="string">&#x27;upper left&#x27;</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p>​<br><img src="/2025/05/04/customer_churn_prediction_model/customer_churn_prediction_model.ipynb_44_0.png" alt="png"><br>​    </p>
<h4 id="2️⃣-InternetService-OnlineSecurity-组合分析"><a href="#2️⃣-InternetService-OnlineSecurity-组合分析" class="headerlink" title="2️⃣ InternetService + OnlineSecurity 组合分析"></a>2️⃣ InternetService + OnlineSecurity 组合分析</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">5</span>))</span><br><span class="line">sns.barplot(data=df, x=<span class="string">&#x27;InternetService&#x27;</span>, y=<span class="string">&#x27;Churn&#x27;</span>, hue=<span class="string">&#x27;OnlineSecurity&#x27;</span>, palette=<span class="string">&#x27;Set1&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;Impact of network type + security service combination on churn rate&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Churn rate&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Network service type&quot;</span>)</span><br><span class="line">plt.legend(title=<span class="string">&#x27;Whether to use security services&#x27;</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p>​<br><img src="/2025/05/04/customer_churn_prediction_model/customer_churn_prediction_model.ipynb_46_0.png" alt="png"><br>​    </p>
<h4 id="3️⃣-MonthlyCharges-tenure（分箱）-组合分析"><a href="#3️⃣-MonthlyCharges-tenure（分箱）-组合分析" class="headerlink" title="3️⃣ MonthlyCharges + tenure（分箱） 组合分析"></a>3️⃣ MonthlyCharges + tenure（分箱） 组合分析</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对 tenure 分箱（划分成新客户、中期客户、老客户）</span></span><br><span class="line">df[<span class="string">&#x27;tenure_group&#x27;</span>] = pd.cut(df[<span class="string">&#x27;tenure&#x27;</span>], bins=[<span class="number">0</span>, <span class="number">12</span>, <span class="number">36</span>, <span class="number">72</span>], labels=[<span class="string">&#x27;短期&#x27;</span>, <span class="string">&#x27;中期&#x27;</span>, <span class="string">&#x27;长期&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将 MonthlyCharges 离散化</span></span><br><span class="line">df[<span class="string">&#x27;charge_level&#x27;</span>] = pd.cut(df[<span class="string">&#x27;MonthlyCharges&#x27;</span>], bins=[<span class="number">0</span>, <span class="number">40</span>, <span class="number">70</span>, <span class="number">120</span>], labels=[<span class="string">&#x27;低&#x27;</span>, <span class="string">&#x27;中&#x27;</span>, <span class="string">&#x27;高&#x27;</span>])</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">sns.barplot(data=df, x=<span class="string">&#x27;tenure_group&#x27;</span>, y=<span class="string">&#x27;Churn&#x27;</span>, hue=<span class="string">&#x27;charge_level&#x27;</span>, palette=<span class="string">&#x27;Set3&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;The impact of monthly consumption level + customer age group on churn rate&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Churn rate&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Customer life cycle stages&quot;</span>)</span><br><span class="line">plt.legend(title=<span class="string">&#x27;Consumption Level&#x27;</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p>​<br><img src="/2025/05/04/customer_churn_prediction_model/customer_churn_prediction_model.ipynb_48_0.png" alt="png"><br>​    </p>
<h2 id="5-建模与评估"><a href="#5-建模与评估" class="headerlink" title="5. 建模与评估"></a>5. 建模与评估</h2><h3 id="5-1-建模"><a href="#5-1-建模" class="headerlink" title="5.1 建模"></a>5.1 建模</h3><h4 id="5-1-1：Logistic-Regression"><a href="#5-1-1：Logistic-Regression" class="headerlink" title="5.1.1：Logistic Regression"></a>5.1.1：Logistic Regression</h4><p>使用标准化后的特征（StandardScaler）训练逻辑回归模型，并使用加权策略（class_weight&#x3D;’balanced’）提升模型对少数类（Churn&#x3D;1）的敏感度。</p>
<hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report, accuracy_score, precision_score, recall_score, f1_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型训练</span></span><br><span class="line">log_model = LogisticRegression(class_weight=<span class="string">&#x27;balanced&#x27;</span>, max_iter=<span class="number">1000</span>, random_state=<span class="number">42</span>)</span><br><span class="line">log_model.fit(X_train_std, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型预测</span></span><br><span class="line">y_pred_log = log_model.predict(X_test_std)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出评估报告</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;📊 Logistic Regression Evaluation:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred_log, target_names=[<span class="string">&quot;Not Churned&quot;</span>, <span class="string">&quot;Churned&quot;</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 单独提取四项核心指标（便于后续汇总）</span></span><br><span class="line">log_metrics = &#123;</span><br><span class="line">    <span class="string">&#x27;Model&#x27;</span>: <span class="string">&#x27;Logistic Regression&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Accuracy&#x27;</span>: accuracy_score(y_test, y_pred_log),</span><br><span class="line">    <span class="string">&#x27;Precision&#x27;</span>: precision_score(y_test, y_pred_log),</span><br><span class="line">    <span class="string">&#x27;Recall&#x27;</span>: recall_score(y_test, y_pred_log),</span><br><span class="line">    <span class="string">&#x27;F1-score&#x27;</span>: f1_score(y_test, y_pred_log)</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>📊 Logistic Regression Evaluation:
              precision    recall  f1-score   support

 Not Churned       0.91      0.70      0.79      1033
     Churned       0.49      0.80      0.61       374

    accuracy                           0.73      1407
   macro avg       0.70      0.75      0.70      1407
weighted avg       0.80      0.73      0.74      1407
</code></pre>
<p>​    </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> ConfusionMatrixDisplay</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">ConfusionMatrixDisplay.from_estimator(</span><br><span class="line">    log_model, X_test_std, y_test,</span><br><span class="line">    display_labels=[<span class="string">&#x27;Not Churned&#x27;</span>, <span class="string">&#x27;Churned&#x27;</span>],</span><br><span class="line">    cmap=plt.cm.Blues</span><br><span class="line">)</span><br><span class="line">plt.title(<span class="string">&quot;Confusion Matrix - Logistic Regression&quot;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p>​<br><img src="/2025/05/04/customer_churn_prediction_model/customer_churn_prediction_model.ipynb_54_0.png" alt="png"><br>​    </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">all_metrics = []</span><br><span class="line">all_metrics.append(log_metrics)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="5-1-2：SVM"><a href="#5-1-2：SVM" class="headerlink" title="5.1.2：SVM"></a>5.1.2：SVM</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report, accuracy_score, precision_score, recall_score, f1_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型训练</span></span><br><span class="line">svm_model = SVC(class_weight=<span class="string">&#x27;balanced&#x27;</span>, kernel=<span class="string">&#x27;rbf&#x27;</span>, probability=<span class="literal">True</span>, random_state=<span class="number">42</span>)</span><br><span class="line">svm_model.fit(X_train_std, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型预测</span></span><br><span class="line">y_pred_svm = svm_model.predict(X_test_std)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出评估报告</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;📊 SVM Evaluation:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred_svm, target_names=[<span class="string">&quot;Not Churned&quot;</span>, <span class="string">&quot;Churned&quot;</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 存储指标结果</span></span><br><span class="line">svm_metrics = &#123;</span><br><span class="line">    <span class="string">&#x27;Model&#x27;</span>: <span class="string">&#x27;Support Vector Machine&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Accuracy&#x27;</span>: accuracy_score(y_test, y_pred_svm),</span><br><span class="line">    <span class="string">&#x27;Precision&#x27;</span>: precision_score(y_test, y_pred_svm),</span><br><span class="line">    <span class="string">&#x27;Recall&#x27;</span>: recall_score(y_test, y_pred_svm),</span><br><span class="line">    <span class="string">&#x27;F1-score&#x27;</span>: f1_score(y_test, y_pred_svm)</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>📊 SVM Evaluation:
              precision    recall  f1-score   support

 Not Churned       0.74      0.40      0.52      1033
     Churned       0.27      0.61      0.38       374

    accuracy                           0.46      1407
   macro avg       0.51      0.51      0.45      1407
weighted avg       0.62      0.46      0.48      1407
</code></pre>
<p>​    </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> ConfusionMatrixDisplay</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">ConfusionMatrixDisplay.from_estimator(</span><br><span class="line">    svm_model, X_test_std, y_test,</span><br><span class="line">    display_labels=[<span class="string">&#x27;Not Churned&#x27;</span>, <span class="string">&#x27;Churned&#x27;</span>],</span><br><span class="line">    cmap=plt.cm.Purples</span><br><span class="line">)</span><br><span class="line">plt.title(<span class="string">&quot;Confusion Matrix - SVM&quot;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p>​<br><img src="/2025/05/04/customer_churn_prediction_model/customer_churn_prediction_model.ipynb_58_0.png" alt="png"><br>​    </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">all_metrics.append(svm_metrics)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="5-1-3：KNN"><a href="#5-1-3：KNN" class="headerlink" title="5.1.3：KNN"></a>5.1.3：KNN</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report, accuracy_score, precision_score, recall_score, f1_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型训练（默认 k=5，可调）</span></span><br><span class="line">knn_model = KNeighborsClassifier(n_neighbors=<span class="number">5</span>)</span><br><span class="line">knn_model.fit(X_train_mm, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型预测</span></span><br><span class="line">y_pred_knn = knn_model.predict(X_test_mm)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出评估报告</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;📊 KNN Evaluation:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred_knn, target_names=[<span class="string">&quot;Not Churned&quot;</span>, <span class="string">&quot;Churned&quot;</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 存储指标结果</span></span><br><span class="line">knn_metrics = &#123;</span><br><span class="line">    <span class="string">&#x27;Model&#x27;</span>: <span class="string">&#x27;K-Nearest Neighbors&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Accuracy&#x27;</span>: accuracy_score(y_test, y_pred_knn),</span><br><span class="line">    <span class="string">&#x27;Precision&#x27;</span>: precision_score(y_test, y_pred_knn),</span><br><span class="line">    <span class="string">&#x27;Recall&#x27;</span>: recall_score(y_test, y_pred_knn),</span><br><span class="line">    <span class="string">&#x27;F1-score&#x27;</span>: f1_score(y_test, y_pred_knn)</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>📊 KNN Evaluation:
              precision    recall  f1-score   support

 Not Churned       0.77      0.86      0.81      1033
     Churned       0.42      0.27      0.33       374

    accuracy                           0.71      1407
   macro avg       0.59      0.57      0.57      1407
weighted avg       0.67      0.71      0.68      1407
</code></pre>
<p>​    </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ConfusionMatrixDisplay.from_estimator(</span><br><span class="line">    knn_model, X_test_mm, y_test,</span><br><span class="line">    display_labels=[<span class="string">&#x27;Not Churned&#x27;</span>, <span class="string">&#x27;Churned&#x27;</span>],</span><br><span class="line">    cmap=plt.cm.Greens</span><br><span class="line">)</span><br><span class="line">plt.title(<span class="string">&quot;Confusion Matrix - KNN&quot;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p>​<br><img src="/2025/05/04/customer_churn_prediction_model/customer_churn_prediction_model.ipynb_62_0.png" alt="png"><br>​    </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">all_metrics.append(knn_metrics)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="5-1-4：Random-Forest"><a href="#5-1-4：Random-Forest" class="headerlink" title="5.1.4：Random Forest"></a>5.1.4：Random Forest</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report, accuracy_score, precision_score, recall_score, f1_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">rf_model = RandomForestClassifier(n_estimators=<span class="number">100</span>, random_state=<span class="number">42</span>)</span><br><span class="line">rf_model.fit(X_train_raw, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测</span></span><br><span class="line">y_pred_rf = rf_model.predict(X_test_raw)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出评估报告</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;📊 Random Forest Evaluation:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred_rf, target_names=[<span class="string">&quot;Not Churned&quot;</span>, <span class="string">&quot;Churned&quot;</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 存储指标</span></span><br><span class="line">rf_metrics = &#123;</span><br><span class="line">    <span class="string">&#x27;Model&#x27;</span>: <span class="string">&#x27;Random Forest&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Accuracy&#x27;</span>: accuracy_score(y_test, y_pred_rf),</span><br><span class="line">    <span class="string">&#x27;Precision&#x27;</span>: precision_score(y_test, y_pred_rf),</span><br><span class="line">    <span class="string">&#x27;Recall&#x27;</span>: recall_score(y_test, y_pred_rf),</span><br><span class="line">    <span class="string">&#x27;F1-score&#x27;</span>: f1_score(y_test, y_pred_rf)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加到总表</span></span><br><span class="line">all_metrics.append(rf_metrics)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>📊 Random Forest Evaluation:
              precision    recall  f1-score   support

 Not Churned       0.83      0.89      0.86      1033
     Churned       0.63      0.51      0.56       374

    accuracy                           0.79      1407
   macro avg       0.73      0.70      0.71      1407
weighted avg       0.78      0.79      0.78      1407
</code></pre>
<p>​    </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ConfusionMatrixDisplay.from_estimator(</span><br><span class="line">    rf_model, X_test_raw, y_test,</span><br><span class="line">    display_labels=[<span class="string">&#x27;Not Churned&#x27;</span>, <span class="string">&#x27;Churned&#x27;</span>],</span><br><span class="line">    cmap=plt.cm.Oranges</span><br><span class="line">)</span><br><span class="line">plt.title(<span class="string">&quot;Confusion Matrix - Random Forest&quot;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p>​<br><img src="/2025/05/04/customer_churn_prediction_model/customer_churn_prediction_model.ipynb_66_0.png" alt="png"><br>​    </p>
<h4 id="5-1-5：XGBoost"><a href="#5-1-5：XGBoost" class="headerlink" title="5.1.5：XGBoost"></a>5.1.5：XGBoost</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report, accuracy_score, precision_score, recall_score, f1_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化并训练模型</span></span><br><span class="line">xgb_model_raw = XGBClassifier(</span><br><span class="line">    use_label_encoder=<span class="literal">False</span>,</span><br><span class="line">    eval_metric=<span class="string">&#x27;logloss&#x27;</span>,</span><br><span class="line">    random_state=<span class="number">42</span></span><br><span class="line">)</span><br><span class="line">xgb_model_raw.fit(X_train_raw, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测</span></span><br><span class="line">y_pred_xgb = xgb_model_raw.predict(X_test_raw)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出评估报告</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;📊 XGBoost Evaluation:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred_xgb, target_names=[<span class="string">&quot;Not Churned&quot;</span>, <span class="string">&quot;Churned&quot;</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 存储指标</span></span><br><span class="line">xgb_metrics = &#123;</span><br><span class="line">    <span class="string">&#x27;Model&#x27;</span>: <span class="string">&#x27;XGBoost&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Accuracy&#x27;</span>: accuracy_score(y_test, y_pred_xgb),</span><br><span class="line">    <span class="string">&#x27;Precision&#x27;</span>: precision_score(y_test, y_pred_xgb),</span><br><span class="line">    <span class="string">&#x27;Recall&#x27;</span>: recall_score(y_test, y_pred_xgb),</span><br><span class="line">    <span class="string">&#x27;F1-score&#x27;</span>: f1_score(y_test, y_pred_xgb)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加到总表</span></span><br><span class="line">all_metrics.append(xgb_metrics)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>📊 XGBoost Evaluation:
              precision    recall  f1-score   support

 Not Churned       0.83      0.87      0.85      1033
     Churned       0.59      0.52      0.55       374

    accuracy                           0.78      1407
   macro avg       0.71      0.69      0.70      1407
weighted avg       0.77      0.78      0.77      1407
</code></pre>
<p>​    </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ConfusionMatrixDisplay.from_estimator(</span><br><span class="line">    xgb_model_raw, X_test_raw, y_test,</span><br><span class="line">    display_labels=[<span class="string">&#x27;Not Churned&#x27;</span>, <span class="string">&#x27;Churned&#x27;</span>],</span><br><span class="line">    cmap=plt.cm.Reds</span><br><span class="line">)</span><br><span class="line">plt.title(<span class="string">&quot;Confusion Matrix - XGBoost&quot;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p>​<br><img src="/2025/05/04/customer_churn_prediction_model/customer_churn_prediction_model.ipynb_69_0.png" alt="png"><br>​    </p>
<h4 id="5-1-6：Neural-Network（MLP）"><a href="#5-1-6：Neural-Network（MLP）" class="headerlink" title="5.1.6：Neural Network（MLP）"></a>5.1.6：Neural Network（MLP）</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neural_network <span class="keyword">import</span> MLPClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report, accuracy_score, precision_score, recall_score, f1_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化神经网络模型</span></span><br><span class="line">mlp_model = MLPClassifier(</span><br><span class="line">    hidden_layer_sizes=(<span class="number">64</span>,),  <span class="comment"># 一个隐层，64个神经元（可调）</span></span><br><span class="line">    activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">    solver=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">    max_iter=<span class="number">300</span>,</span><br><span class="line">    random_state=<span class="number">42</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型训练</span></span><br><span class="line">mlp_model.fit(X_train_mm, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型预测</span></span><br><span class="line">y_pred_mlp = mlp_model.predict(X_test_mm)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出评估报告</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;📊 Neural Network (MLP) Evaluation:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred_mlp, target_names=[<span class="string">&quot;Not Churned&quot;</span>, <span class="string">&quot;Churned&quot;</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 存储指标</span></span><br><span class="line">mlp_metrics = &#123;</span><br><span class="line">    <span class="string">&#x27;Model&#x27;</span>: <span class="string">&#x27;Neural Network (MLP)&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Accuracy&#x27;</span>: accuracy_score(y_test, y_pred_mlp),</span><br><span class="line">    <span class="string">&#x27;Precision&#x27;</span>: precision_score(y_test, y_pred_mlp),</span><br><span class="line">    <span class="string">&#x27;Recall&#x27;</span>: recall_score(y_test, y_pred_mlp),</span><br><span class="line">    <span class="string">&#x27;F1-score&#x27;</span>: f1_score(y_test, y_pred_mlp)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加到汇总列表</span></span><br><span class="line">all_metrics.append(mlp_metrics)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>📊 Neural Network (MLP) Evaluation:
              precision    recall  f1-score   support

 Not Churned       0.74      0.98      0.85      1033
     Churned       0.55      0.06      0.10       374

    accuracy                           0.74      1407
   macro avg       0.65      0.52      0.47      1407
weighted avg       0.69      0.74      0.65      1407
</code></pre>
<p>​    </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ConfusionMatrixDisplay.from_estimator(</span><br><span class="line">    mlp_model, X_test_mm, y_test,</span><br><span class="line">    display_labels=[<span class="string">&#x27;Not Churned&#x27;</span>, <span class="string">&#x27;Churned&#x27;</span>],</span><br><span class="line">    cmap=plt.cm.Blues</span><br><span class="line">)</span><br><span class="line">plt.title(<span class="string">&quot;Confusion Matrix - Neural Network (MLP)&quot;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p>​<br><img src="/2025/05/04/customer_churn_prediction_model/customer_churn_prediction_model.ipynb_72_0.png" alt="png"><br>​    </p>
<h3 id="5-2-评估指标（Accuracy、Recall、F1、ROC）"><a href="#5-2-评估指标（Accuracy、Recall、F1、ROC）" class="headerlink" title="5.2 评估指标（Accuracy、Recall、F1、ROC）"></a>5.2 评估指标（Accuracy、Recall、F1、ROC）</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">df_metrics = pd.DataFrame(all_metrics)</span><br><span class="line">display(df_metrics.sort_values(by=<span class="string">&#x27;F1-score&#x27;</span>, ascending=<span class="literal">False</span>))</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Model</th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1-score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Logistic Regression</td>
      <td>0.727079</td>
      <td>0.491803</td>
      <td>0.802139</td>
      <td>0.609756</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Random Forest</td>
      <td>0.788913</td>
      <td>0.627063</td>
      <td>0.508021</td>
      <td>0.561300</td>
    </tr>
    <tr>
      <th>4</th>
      <td>XGBoost</td>
      <td>0.777541</td>
      <td>0.593272</td>
      <td>0.518717</td>
      <td>0.553495</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Support Vector Machine</td>
      <td>0.459844</td>
      <td>0.271327</td>
      <td>0.612299</td>
      <td>0.376026</td>
    </tr>
    <tr>
      <th>2</th>
      <td>K-Nearest Neighbors</td>
      <td>0.705757</td>
      <td>0.416667</td>
      <td>0.267380</td>
      <td>0.325733</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Neural Network (MLP)</td>
      <td>0.737029</td>
      <td>0.552632</td>
      <td>0.056150</td>
      <td>0.101942</td>
    </tr>
  </tbody>
</table>
</div>


<h4 id="模型评估结果分析（初步）"><a href="#模型评估结果分析（初步）" class="headerlink" title="模型评估结果分析（初步）"></a>模型评估结果分析（初步）</h4><p>🔍 初步结论：</p>
<ul>
<li><strong>逻辑回归（Logistic Regression）</strong> 表现最为稳定，在保持良好精度的同时，Recall 达到 80%，说明对“客户流失”这一少数类的识别能力较强，是当前表现最均衡的基线模型。</li>
<li><strong>随机森林（Random Forest）与 XGBoost</strong> 在准确率上领先，但 Recall 略低，说明它们更擅长识别多数类客户，可能导致部分流失客户被错判为未流失。</li>
<li><strong>KNN、SVM 与神经网络（MLP）</strong> 表现不佳，尤其是 MLP 的 Recall 极低，说明其对小数据集、高维特征不敏感，存在明显的欠拟合问题。</li>
</ul>
<hr>
<p>📌 后续优化方向建议：</p>
<ol>
<li><strong>特征重要性分析</strong>：提取前 10 个重要特征，尝试简化输入维度。</li>
<li><strong>模型可解释性增强</strong>：使用 SHAP 分析 XGBoost 的特征影响方向与强度。</li>
<li><strong>构建轻量模型</strong>：仅使用 Top-N 特征训练 LR &#x2F; XGBoost，对比性能变化。</li>
<li><strong>提升 Precision</strong>：通过阈值调优、模型融合等方式，进一步提高预测结果的可靠性。</li>
</ol>
<h2 id="6-模型解释"><a href="#6-模型解释" class="headerlink" title="6. 模型解释"></a>6. 模型解释</h2><h3 id="6-1-提取特征重要性排名（柱状图"><a href="#6-1-提取特征重要性排名（柱状图" class="headerlink" title="6.1 提取特征重要性排名（柱状图)"></a>6.1 提取特征重要性排名（柱状图)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取特征重要性</span></span><br><span class="line">feature_importance = pd.DataFrame(&#123;</span><br><span class="line">    <span class="string">&#x27;feature&#x27;</span>: X_train_raw.columns,</span><br><span class="line">    <span class="string">&#x27;importance&#x27;</span>: xgb_model_raw.feature_importances_</span><br><span class="line">&#125;).sort_values(by=<span class="string">&#x27;importance&#x27;</span>, ascending=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化前 10 个特征</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">sns.barplot(data=feature_importance.head(<span class="number">10</span>), x=<span class="string">&#x27;importance&#x27;</span>, y=<span class="string">&#x27;feature&#x27;</span>, palette=<span class="string">&#x27;viridis&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;XGBoost Top 10 Feature Importance&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;Importance&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Feature&quot;</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p>​<br><img src="/2025/05/04/customer_churn_prediction_model/customer_churn_prediction_model.ipynb_79_0.png" alt="png"><br>​    </p>
<h3 id="6-2-XGBoost-内置特征重要性（Gain）"><a href="#6-2-XGBoost-内置特征重要性（Gain）" class="headerlink" title="6.2 XGBoost 内置特征重要性（Gain）"></a>6.2 XGBoost 内置特征重要性（Gain）</h3><p>如下图所示，XGBoost 的 <code>feature_importances_</code> 属性给出了每个特征对模型分裂节点“增益贡献”的平均占比。</p>
<ul>
<li><strong>Contract（合约类型）</strong> 显著高于其他特征，是模型预测客户是否流失的首要依据。</li>
<li>其他较重要特征包括：<code>InternetService</code>, <code>PhoneService</code>, <code>tenure</code>, <code>StreamingTV</code>, <code>TechSupport</code>。</li>
<li>此方法虽然高效直观，但<strong>不考虑特征间交互</strong>，且对同类特征的刻画较粗。</li>
</ul>
<h2 id="7-重建模型-特征选取-构造"><a href="#7-重建模型-特征选取-构造" class="headerlink" title="7. 重建模型 特征选取&#x2F;构造"></a>7. 重建模型 特征选取&#x2F;构造</h2><h3 id="7-1-选取重要特征重建模型"><a href="#7-1-选取重要特征重建模型" class="headerlink" title="7.1 选取重要特征重建模型"></a>7.1 选取重要特征重建模型</h3><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Model</th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1-score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Logistic Regression</td>
      <td>0.727079</td>
      <td>0.491803</td>
      <td>0.802139</td>
      <td>0.609756</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Random Forest</td>
      <td>0.788913</td>
      <td>0.627063</td>
      <td>0.508021</td>
      <td>0.561300</td>
    </tr>
    <tr>
      <th>4</th>
      <td>XGBoost</td>
      <td>0.777541</td>
      <td>0.593272</td>
      <td>0.518717</td>
      <td>0.553495</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Support Vector Machine</td>
      <td>0.459844</td>
      <td>0.271327</td>
      <td>0.612299</td>
      <td>0.376026</td>
    </tr>
    <tr>
      <th>2</th>
      <td>K-Nearest Neighbors</td>
      <td>0.705757</td>
      <td>0.416667</td>
      <td>0.267380</td>
      <td>0.325733</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Neural Network (MLP)</td>
      <td>0.737029</td>
      <td>0.552632</td>
      <td>0.056150</td>
      <td>0.101942</td>
    </tr>
  </tbody>
</table>
</div>

<p>鉴于初步结果：</p>
<p>我们将在下一阶段优化中保留以下三类表现优异的模型：Logistic Regression、Random Forest 与 XGBoost。</p>
<p>它们在当前全特征下均表现出色，F1 分数领先，且各自具备不同优势：</p>
<p>Logistic Regression 具备高解释性与良好的 Recall</p>
<p>Random Forest 准确率与精度兼顾</p>
<p>XGBoost 综合能力强，并支持高级可解释性分析（如 SHAP）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">top10_features = [</span><br><span class="line">    <span class="string">&#x27;Contract&#x27;</span>, <span class="string">&#x27;MonthlyCharges&#x27;</span>, <span class="string">&#x27;tenure&#x27;</span>, <span class="string">&#x27;TotalCharges&#x27;</span>,<span class="string">&#x27;PaperlessBilling&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;PaymentMethod&#x27;</span>, <span class="string">&#x27;InternetService&#x27;</span>, <span class="string">&#x27;OnlineSecurity&#x27;</span>, <span class="string">&#x27;MultipleLines&#x27;</span>, <span class="string">&#x27;TechSupport&#x27;</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建新的数据集</span></span><br><span class="line">X_train_top10 = X_train_raw[top10_features]</span><br><span class="line">X_test_top10 = X_test_raw[top10_features]</span><br></pre></td></tr></table></figure>

<h4 id="7-1-1-Logistic-Regression"><a href="#7-1-1-Logistic-Regression" class="headerlink" title="7.1.1 Logistic Regression"></a>7.1.1 Logistic Regression</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score, precision_score, recall_score, f1_score</span><br><span class="line"></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">X_train_top10_std = scaler.fit_transform(X_train_top10)</span><br><span class="line">X_test_top10_std = scaler.transform(X_test_top10)</span><br><span class="line"></span><br><span class="line">lr_top10 = LogisticRegression(class_weight=<span class="string">&#x27;balanced&#x27;</span>, max_iter=<span class="number">1000</span>, random_state=<span class="number">42</span>)</span><br><span class="line">lr_top10.fit(X_train_top10_std, y_train)</span><br><span class="line">y_pred_lr_top10 = lr_top10.predict(X_test_top10_std)</span><br><span class="line"></span><br><span class="line">lr_top10_metrics = &#123;</span><br><span class="line">    <span class="string">&#x27;Model&#x27;</span>: <span class="string">&#x27;Logistic Regression (Top 10)&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Accuracy&#x27;</span>: accuracy_score(y_test, y_pred_lr_top10),</span><br><span class="line">    <span class="string">&#x27;Precision&#x27;</span>: precision_score(y_test, y_pred_lr_top10),</span><br><span class="line">    <span class="string">&#x27;Recall&#x27;</span>: recall_score(y_test, y_pred_lr_top10),</span><br><span class="line">    <span class="string">&#x27;F1-score&#x27;</span>: f1_score(y_test, y_pred_lr_top10)</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="7-1-2-Random-Forest"><a href="#7-1-2-Random-Forest" class="headerlink" title="7.1.2 Random Forest"></a>7.1.2 Random Forest</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"></span><br><span class="line">rf_top10 = RandomForestClassifier(n_estimators=<span class="number">100</span>, random_state=<span class="number">42</span>)</span><br><span class="line">rf_top10.fit(X_train_top10, y_train)</span><br><span class="line">y_pred_rf_top10 = rf_top10.predict(X_test_top10)</span><br><span class="line"></span><br><span class="line">rf_top10_metrics = &#123;</span><br><span class="line">    <span class="string">&#x27;Model&#x27;</span>: <span class="string">&#x27;Random Forest (Top 10)&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Accuracy&#x27;</span>: accuracy_score(y_test, y_pred_rf_top10),</span><br><span class="line">    <span class="string">&#x27;Precision&#x27;</span>: precision_score(y_test, y_pred_rf_top10),</span><br><span class="line">    <span class="string">&#x27;Recall&#x27;</span>: recall_score(y_test, y_pred_rf_top10),</span><br><span class="line">    <span class="string">&#x27;F1-score&#x27;</span>: f1_score(y_test, y_pred_rf_top10)</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="7-1-3-XGBoost"><a href="#7-1-3-XGBoost" class="headerlink" title="7.1.3 XGBoost"></a>7.1.3 XGBoost</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line"></span><br><span class="line">xgb_top10 = XGBClassifier(use_label_encoder=<span class="literal">False</span>, eval_metric=<span class="string">&#x27;logloss&#x27;</span>, random_state=<span class="number">42</span>)</span><br><span class="line">xgb_top10.fit(X_train_top10, y_train)</span><br><span class="line">y_pred_xgb_top10 = xgb_top10.predict(X_test_top10)</span><br><span class="line"></span><br><span class="line">xgb_top10_metrics = &#123;</span><br><span class="line">    <span class="string">&#x27;Model&#x27;</span>: <span class="string">&#x27;XGBoost (Top 10)&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Accuracy&#x27;</span>: accuracy_score(y_test, y_pred_xgb_top10),</span><br><span class="line">    <span class="string">&#x27;Precision&#x27;</span>: precision_score(y_test, y_pred_xgb_top10),</span><br><span class="line">    <span class="string">&#x27;Recall&#x27;</span>: recall_score(y_test, y_pred_xgb_top10),</span><br><span class="line">    <span class="string">&#x27;F1-score&#x27;</span>: f1_score(y_test, y_pred_xgb_top10)</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="7-1-4-打包输出"><a href="#7-1-4-打包输出" class="headerlink" title="7.1.4 打包输出"></a>7.1.4 打包输出</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">top10_results = [lr_top10_metrics, rf_top10_metrics, xgb_top10_metrics]</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df_top10 = pd.DataFrame(top10_results)</span><br><span class="line">display(df_top10)</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Model</th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1-score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Logistic Regression (Top 10)</td>
      <td>0.721393</td>
      <td>0.485669</td>
      <td>0.815508</td>
      <td>0.608782</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Random Forest (Top 10)</td>
      <td>0.780384</td>
      <td>0.604502</td>
      <td>0.502674</td>
      <td>0.548905</td>
    </tr>
    <tr>
      <th>2</th>
      <td>XGBoost (Top 10)</td>
      <td>0.769012</td>
      <td>0.574924</td>
      <td>0.502674</td>
      <td>0.536377</td>
    </tr>
  </tbody>
</table>
</div>


<h3 id="7-2-特征构造"><a href="#7-2-特征构造" class="headerlink" title="7.2 特征构造"></a>7.2 特征构造</h3><table>
<thead>
<tr>
<th>特征名</th>
<th>类型</th>
<th>构造方式</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td><code>AvgCharges</code></td>
<td>数值型</td>
<td><code>TotalCharges / tenure</code></td>
<td>每月平均花费，反映客户价值（注意除以 0 的处理）</td>
</tr>
<tr>
<td><code>Contract_MonthlyInteraction</code></td>
<td>数值型</td>
<td><code>Contract编码 × MonthlyCharges</code></td>
<td>合约类型与消费的交互，捕捉高月费短约客户风险</td>
</tr>
<tr>
<td><code>TenureGroup</code></td>
<td>类别型</td>
<td>tenure 分箱（0-12，12-36，36-72）</td>
<td>将使用时长分组，更便于模型理解客户阶段</td>
</tr>
<tr>
<td><code>IsHighValueCustomer</code></td>
<td>布尔型</td>
<td><code>MonthlyCharges &gt; 80</code></td>
<td>高消费客户识别，标记为高价值敏感用户</td>
</tr>
<tr>
<td><code>ServiceCount</code></td>
<td>数值型</td>
<td>统计客户启用的服务项数量</td>
<td>服务越多代表黏性越强（如 TechSupport、StreamingTV 等）</td>
</tr>
</tbody></table>
<h4 id="7-3-1-构造增强特征函数"><a href="#7-3-1-构造增强特征函数" class="headerlink" title="7.3.1 构造增强特征函数"></a>7.3.1 构造增强特征函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add_constructed_features</span>(<span class="params">df</span>):</span><br><span class="line">    df = df.copy()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Average monthly charges</span></span><br><span class="line">    df[<span class="string">&#x27;AvgCharges&#x27;</span>] = df[<span class="string">&#x27;TotalCharges&#x27;</span>] / df[<span class="string">&#x27;tenure&#x27;</span>]</span><br><span class="line">    df[<span class="string">&#x27;AvgCharges&#x27;</span>].replace([np.inf, -np.inf], <span class="number">0</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">    df[<span class="string">&#x27;AvgCharges&#x27;</span>].fillna(<span class="number">0</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Contract type × MonthlyCharges</span></span><br><span class="line">    df[<span class="string">&#x27;Contract_MonthlyInteraction&#x27;</span>] = df[<span class="string">&#x27;Contract&#x27;</span>] * df[<span class="string">&#x27;MonthlyCharges&#x27;</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Tenure group binning</span></span><br><span class="line">    df[<span class="string">&#x27;TenureGroup&#x27;</span>] = pd.cut(df[<span class="string">&#x27;tenure&#x27;</span>], bins=[<span class="number">0</span>, <span class="number">12</span>, <span class="number">36</span>, <span class="number">72</span>], labels=[<span class="string">&#x27;New&#x27;</span>, <span class="string">&#x27;Mid&#x27;</span>, <span class="string">&#x27;Long&#x27;</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># High-value customer indicator</span></span><br><span class="line">    df[<span class="string">&#x27;IsHighValueCustomer&#x27;</span>] = (df[<span class="string">&#x27;MonthlyCharges&#x27;</span>] &gt; <span class="number">80</span>).astype(<span class="built_in">int</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Total active services</span></span><br><span class="line">    service_cols = [<span class="string">&#x27;OnlineSecurity&#x27;</span>, <span class="string">&#x27;OnlineBackup&#x27;</span>, <span class="string">&#x27;DeviceProtection&#x27;</span>, </span><br><span class="line">                    <span class="string">&#x27;TechSupport&#x27;</span>, <span class="string">&#x27;StreamingTV&#x27;</span>, <span class="string">&#x27;StreamingMovies&#x27;</span>]</span><br><span class="line">    df[<span class="string">&#x27;ServiceCount&#x27;</span>] = df[service_cols].apply(<span class="keyword">lambda</span> row: <span class="built_in">sum</span>(row == <span class="string">&#x27;Yes&#x27;</span>), axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> df</span><br><span class="line"><span class="comment"># 应用构造特征</span></span><br><span class="line">X_train_enhanced = add_constructed_features(X_train_raw)</span><br><span class="line">X_test_enhanced = add_constructed_features(X_test_raw)</span><br></pre></td></tr></table></figure>

<h4 id="7-3-2-特征预处理"><a href="#7-3-2-特征预处理" class="headerlink" title="7.3.2 特征预处理"></a>7.3.2 特征预处理</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># ✅ Top10 原始特征列</span></span><br><span class="line">top10_features = [</span><br><span class="line">    <span class="string">&#x27;Contract&#x27;</span>, <span class="string">&#x27;tenure&#x27;</span>, <span class="string">&#x27;MonthlyCharges&#x27;</span>, <span class="string">&#x27;TotalCharges&#x27;</span>, <span class="string">&#x27;InternetService&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;OnlineSecurity&#x27;</span>, <span class="string">&#x27;TechSupport&#x27;</span>, <span class="string">&#x27;PaymentMethod&#x27;</span>, <span class="string">&#x27;PaperlessBilling&#x27;</span>, <span class="string">&#x27;SeniorCitizen&#x27;</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># ✅ 构造特征列（确保这些都在构造函数中定义过）</span></span><br><span class="line">constructed_features = [</span><br><span class="line">    <span class="string">&#x27;AvgCharges&#x27;</span>, <span class="string">&#x27;Contract_MonthlyInteraction&#x27;</span>, <span class="string">&#x27;IsHighValueCustomer&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;ServiceCount&#x27;</span>, <span class="string">&#x27;TenureGroup&#x27;</span>  <span class="comment"># TenureGroup 是待编码变量</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># ✅ 组合总特征列表（此处不包括 TenureGroup 的 One-Hot 结果）</span></span><br><span class="line">final_raw_features = top10_features + constructed_features</span><br><span class="line"></span><br><span class="line"><span class="comment"># ✅ 提取子集（先不处理 One-Hot 编码）</span></span><br><span class="line">X_train_sub = X_train_enhanced[final_raw_features].copy()</span><br><span class="line">X_test_sub = X_test_enhanced[final_raw_features].copy()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ✅ 对 TenureGroup 进行 OneHot 编码（drop=&#x27;first&#x27; 避免冗余）</span></span><br><span class="line">encoder = OneHotEncoder(drop=<span class="string">&#x27;first&#x27;</span>, sparse_output=<span class="literal">False</span>, handle_unknown=<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line">encoded_train = encoder.fit_transform(X_train_sub[[<span class="string">&#x27;TenureGroup&#x27;</span>]])</span><br><span class="line">encoded_test = encoder.transform(X_test_sub[[<span class="string">&#x27;TenureGroup&#x27;</span>]])</span><br><span class="line">encoded_cols = encoder.get_feature_names_out([<span class="string">&#x27;TenureGroup&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># ✅ 拼接回去（并删除原始 TenureGroup）</span></span><br><span class="line">X_train_encoded = pd.DataFrame(encoded_train, columns=encoded_cols, index=X_train_sub.index)</span><br><span class="line">X_test_encoded = pd.DataFrame(encoded_test, columns=encoded_cols, index=X_test_sub.index)</span><br><span class="line"></span><br><span class="line">X_train_enhanced_clean = pd.concat([X_train_sub.drop(columns=[<span class="string">&#x27;TenureGroup&#x27;</span>]), X_train_encoded], axis=<span class="number">1</span>)</span><br><span class="line">X_test_enhanced_clean = pd.concat([X_test_sub.drop(columns=[<span class="string">&#x27;TenureGroup&#x27;</span>]), X_test_encoded], axis=<span class="number">1</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="7-4-1-Logistic-Regression（基于TOP10-增强特征）"><a href="#7-4-1-Logistic-Regression（基于TOP10-增强特征）" class="headerlink" title="7.4.1 Logistic Regression（基于TOP10 + 增强特征）"></a>7.4.1 Logistic Regression（基于TOP10 + 增强特征）</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 标准化数值列（只针对 Logistic Regression）</span></span><br><span class="line">numeric_cols = [<span class="string">&#x27;tenure&#x27;</span>, <span class="string">&#x27;MonthlyCharges&#x27;</span>, <span class="string">&#x27;TotalCharges&#x27;</span>, <span class="string">&#x27;AvgCharges&#x27;</span>, <span class="string">&#x27;ServiceCount&#x27;</span>, <span class="string">&#x27;Contract_MonthlyInteraction&#x27;</span>]</span><br><span class="line"></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">X_train_log = X_train_enhanced_clean.copy()</span><br><span class="line">X_test_log = X_test_enhanced_clean.copy()</span><br><span class="line"></span><br><span class="line">X_train_log[numeric_cols] = scaler.fit_transform(X_train_log[numeric_cols])</span><br><span class="line">X_test_log[numeric_cols] = scaler.transform(X_test_log[numeric_cols])</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score, precision_score, recall_score, f1_score</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型训练</span></span><br><span class="line">lr_model = LogisticRegression(class_weight=<span class="string">&#x27;balanced&#x27;</span>, max_iter=<span class="number">1000</span>, random_state=<span class="number">42</span>)</span><br><span class="line">lr_model.fit(X_train_log, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测</span></span><br><span class="line">y_pred_lr = lr_model.predict(X_test_log)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 指标汇总</span></span><br><span class="line">lr_metrics = &#123;</span><br><span class="line">    <span class="string">&#x27;Model&#x27;</span>: <span class="string">&#x27;Logistic Regression (Top10 + Constructed)&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Accuracy&#x27;</span>: accuracy_score(y_test, y_pred_lr),</span><br><span class="line">    <span class="string">&#x27;Precision&#x27;</span>: precision_score(y_test, y_pred_lr),</span><br><span class="line">    <span class="string">&#x27;Recall&#x27;</span>: recall_score(y_test, y_pred_lr),</span><br><span class="line">    <span class="string">&#x27;F1-score&#x27;</span>: f1_score(y_test, y_pred_lr)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 展示结果</span></span><br><span class="line">pd.DataFrame([lr_metrics])</span><br><span class="line"></span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Model</th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1-score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Logistic Regression (Top10 + Constructed)</td>
      <td>0.716418</td>
      <td>0.480253</td>
      <td>0.812834</td>
      <td>0.603774</td>
    </tr>
  </tbody>
</table>
</div>



<h4 id="7-4-2-Random-Forest（基于-Top10-构造特征）"><a href="#7-4-2-Random-Forest（基于-Top10-构造特征）" class="headerlink" title="7.4.2 Random Forest（基于 Top10 + 构造特征）"></a>7.4.2 Random Forest（基于 Top10 + 构造特征）</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score, precision_score, recall_score, f1_score</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型训练</span></span><br><span class="line">rf_model = RandomForestClassifier(n_estimators=<span class="number">100</span>, random_state=<span class="number">42</span>)</span><br><span class="line">rf_model.fit(X_train_enhanced_clean, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测</span></span><br><span class="line">y_pred_rf = rf_model.predict(X_test_enhanced_clean)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型评估</span></span><br><span class="line">rf_metrics = &#123;</span><br><span class="line">    <span class="string">&#x27;Model&#x27;</span>: <span class="string">&#x27;Random Forest (Top10 + Constructed)&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Accuracy&#x27;</span>: accuracy_score(y_test, y_pred_rf),</span><br><span class="line">    <span class="string">&#x27;Precision&#x27;</span>: precision_score(y_test, y_pred_rf),</span><br><span class="line">    <span class="string">&#x27;Recall&#x27;</span>: recall_score(y_test, y_pred_rf),</span><br><span class="line">    <span class="string">&#x27;F1-score&#x27;</span>: f1_score(y_test, y_pred_rf)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 展示结果</span></span><br><span class="line">pd.DataFrame([rf_metrics])</span><br><span class="line"></span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Model</th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1-score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Random Forest (Top10 + Constructed)</td>
      <td>0.779673</td>
      <td>0.604575</td>
      <td>0.494652</td>
      <td>0.544118</td>
    </tr>
  </tbody>
</table>
</div>



<h4 id="7-4-3-XGBoost（基于-Top10-构造特征）"><a href="#7-4-3-XGBoost（基于-Top10-构造特征）" class="headerlink" title="7.4.3 XGBoost（基于 Top10 + 构造特征）"></a>7.4.3 XGBoost（基于 Top10 + 构造特征）</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score, precision_score, recall_score, f1_score</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型训练</span></span><br><span class="line">xgb_model = XGBClassifier(use_label_encoder=<span class="literal">False</span>, eval_metric=<span class="string">&#x27;logloss&#x27;</span>, random_state=<span class="number">42</span>)</span><br><span class="line">xgb_model.fit(X_train_enhanced_clean, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测</span></span><br><span class="line">y_pred_xgb = xgb_model.predict(X_test_enhanced_clean)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型评估</span></span><br><span class="line">xgb_metrics = &#123;</span><br><span class="line">    <span class="string">&#x27;Model&#x27;</span>: <span class="string">&#x27;XGBoost (Top10 + Constructed)&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Accuracy&#x27;</span>: accuracy_score(y_test, y_pred_xgb),</span><br><span class="line">    <span class="string">&#x27;Precision&#x27;</span>: precision_score(y_test, y_pred_xgb),</span><br><span class="line">    <span class="string">&#x27;Recall&#x27;</span>: recall_score(y_test, y_pred_xgb),</span><br><span class="line">    <span class="string">&#x27;F1-score&#x27;</span>: f1_score(y_test, y_pred_xgb)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 展示结果</span></span><br><span class="line">pd.DataFrame([xgb_metrics])</span><br><span class="line"></span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Model</th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1-score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>XGBoost (Top10 + Constructed)</td>
      <td>0.771144</td>
      <td>0.578788</td>
      <td>0.510695</td>
      <td>0.542614</td>
    </tr>
  </tbody>
</table>
</div>



<h3 id="7-4-汇总"><a href="#7-4-汇总" class="headerlink" title="7.4 汇总"></a>7.4 汇总</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将三个结果字典合并为列表</span></span><br><span class="line">all_metrics = [lr_metrics, rf_metrics, xgb_metrics]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 转为 DataFrame 并按 F1-score 排序</span></span><br><span class="line">results_df = pd.DataFrame(all_metrics).sort_values(by=<span class="string">&#x27;F1-score&#x27;</span>, ascending=<span class="literal">False</span>).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 展示结果</span></span><br><span class="line">results_df.style.set_caption(<span class="string">&quot;🔍 Model Comparison (Top10 + Constructed Features)&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>




<style type="text/css">
</style>
<table id="T_d1be8">
  <caption>🔍 Model Comparison (Top10 + Constructed Features)</caption>
  <thead>
    <tr>
      <th class="blank level0">&nbsp;</th>
      <th id="T_d1be8_level0_col0" class="col_heading level0 col0">Model</th>
      <th id="T_d1be8_level0_col1" class="col_heading level0 col1">Accuracy</th>
      <th id="T_d1be8_level0_col2" class="col_heading level0 col2">Precision</th>
      <th id="T_d1be8_level0_col3" class="col_heading level0 col3">Recall</th>
      <th id="T_d1be8_level0_col4" class="col_heading level0 col4">F1-score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_d1be8_level0_row0" class="row_heading level0 row0">0</th>
      <td id="T_d1be8_row0_col0" class="data row0 col0">Logistic Regression (Top10 + Constructed)</td>
      <td id="T_d1be8_row0_col1" class="data row0 col1">0.716418</td>
      <td id="T_d1be8_row0_col2" class="data row0 col2">0.480253</td>
      <td id="T_d1be8_row0_col3" class="data row0 col3">0.812834</td>
      <td id="T_d1be8_row0_col4" class="data row0 col4">0.603774</td>
    </tr>
    <tr>
      <th id="T_d1be8_level0_row1" class="row_heading level0 row1">1</th>
      <td id="T_d1be8_row1_col0" class="data row1 col0">Random Forest (Top10 + Constructed)</td>
      <td id="T_d1be8_row1_col1" class="data row1 col1">0.779673</td>
      <td id="T_d1be8_row1_col2" class="data row1 col2">0.604575</td>
      <td id="T_d1be8_row1_col3" class="data row1 col3">0.494652</td>
      <td id="T_d1be8_row1_col4" class="data row1 col4">0.544118</td>
    </tr>
    <tr>
      <th id="T_d1be8_level0_row2" class="row_heading level0 row2">2</th>
      <td id="T_d1be8_row2_col0" class="data row2 col0">XGBoost (Top10 + Constructed)</td>
      <td id="T_d1be8_row2_col1" class="data row2 col1">0.771144</td>
      <td id="T_d1be8_row2_col2" class="data row2 col2">0.578788</td>
      <td id="T_d1be8_row2_col3" class="data row2 col3">0.510695</td>
      <td id="T_d1be8_row2_col4" class="data row2 col4">0.542614</td>
    </tr>
  </tbody>
</table>




<h2 id="8-不同特征选取-建模结果对比"><a href="#8-不同特征选取-建模结果对比" class="headerlink" title="8. 不同特征选取 建模结果对比"></a>8. 不同特征选取 建模结果对比</h2><h4 id="全特征"><a href="#全特征" class="headerlink" title="全特征"></a>全特征</h4><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Model</th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1-score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Logistic Regression</td>
      <td>0.727079</td>
      <td>0.491803</td>
      <td>0.802139</td>
      <td>0.609756</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Random Forest</td>
      <td>0.788913</td>
      <td>0.627063</td>
      <td>0.508021</td>
      <td>0.561300</td>
    </tr>
    <tr>
      <th>4</th>
      <td>XGBoost</td>
      <td>0.777541</td>
      <td>0.593272</td>
      <td>0.518717</td>
      <td>0.553495</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Support Vector Machine</td>
      <td>0.459844</td>
      <td>0.271327</td>
      <td>0.612299</td>
      <td>0.376026</td>
    </tr>
    <tr>
      <th>2</th>
      <td>K-Nearest Neighbors</td>
      <td>0.705757</td>
      <td>0.416667</td>
      <td>0.267380</td>
      <td>0.325733</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Neural Network (MLP)</td>
      <td>0.737029</td>
      <td>0.552632</td>
      <td>0.056150</td>
      <td>0.101942</td>
    </tr>
  </tbody>
</table>
</div>

<h4 id="TOP10"><a href="#TOP10" class="headerlink" title="TOP10"></a>TOP10</h4><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Model</th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1-score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Logistic Regression (Top 10)</td>
      <td>0.723525</td>
      <td>0.487685</td>
      <td>0.794118</td>
      <td>0.604273</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Random Forest (Top 10)</td>
      <td>0.783227</td>
      <td>0.610932</td>
      <td>0.508021</td>
      <td>0.554745</td>
    </tr>
    <tr>
      <th>2</th>
      <td>XGBoost (Top 10)</td>
      <td>0.782516</td>
      <td>0.600592</td>
      <td>0.542781</td>
      <td>0.570225</td>
    </tr>
  </tbody>
</table>
</div>

<h4 id="TOP10-构造特征"><a href="#TOP10-构造特征" class="headerlink" title="TOP10 + 构造特征"></a>TOP10 + 构造特征</h4><style type="text/css">
</style>
<table id="T_1f199">
  <caption>🔍 Model Comparison (Top10 + Constructed Features)</caption>
  <thead>
    <tr>
      <th class="blank level0">&nbsp;</th>
      <th id="T_1f199_level0_col0" class="col_heading level0 col0">Model</th>
      <th id="T_1f199_level0_col1" class="col_heading level0 col1">Accuracy</th>
      <th id="T_1f199_level0_col2" class="col_heading level0 col2">Precision</th>
      <th id="T_1f199_level0_col3" class="col_heading level0 col3">Recall</th>
      <th id="T_1f199_level0_col4" class="col_heading level0 col4">F1-score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_1f199_level0_row0" class="row_heading level0 row0">0</th>
      <td id="T_1f199_row0_col0" class="data row0 col0">Logistic Regression (Top10 + Constructed)</td>
      <td id="T_1f199_row0_col1" class="data row0 col1">0.716418</td>
      <td id="T_1f199_row0_col2" class="data row0 col2">0.480253</td>
      <td id="T_1f199_row0_col3" class="data row0 col3">0.812834</td>
      <td id="T_1f199_row0_col4" class="data row0 col4">0.603774</td>
    </tr>
    <tr>
      <th id="T_1f199_level0_row1" class="row_heading level0 row1">1</th>
      <td id="T_1f199_row1_col0" class="data row1 col0">Random Forest (Top10 + Constructed)</td>
      <td id="T_1f199_row1_col1" class="data row1 col1">0.779673</td>
      <td id="T_1f199_row1_col2" class="data row1 col2">0.604575</td>
      <td id="T_1f199_row1_col3" class="data row1 col3">0.494652</td>
      <td id="T_1f199_row1_col4" class="data row1 col4">0.544118</td>
    </tr>
    <tr>
      <th id="T_1f199_level0_row2" class="row_heading level0 row2">2</th>
      <td id="T_1f199_row2_col0" class="data row2 col0">XGBoost (Top10 + Constructed)</td>
      <td id="T_1f199_row2_col1" class="data row2 col1">0.771144</td>
      <td id="T_1f199_row2_col2" class="data row2 col2">0.578788</td>
      <td id="T_1f199_row2_col3" class="data row2 col3">0.510695</td>
      <td id="T_1f199_row2_col4" class="data row2 col4">0.542614</td>
    </tr>
  </tbody>
</table>

<h2 id="9-SHAP-分析（基于XGBoost-选取不同特征进行）"><a href="#9-SHAP-分析（基于XGBoost-选取不同特征进行）" class="headerlink" title="9. SHAP 分析（基于XGBoost 选取不同特征进行）"></a>9. SHAP 分析（基于XGBoost 选取不同特征进行）</h2><h3 id="9-1-全特征"><a href="#9-1-全特征" class="headerlink" title="9.1 全特征"></a>9.1 全特征</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> shap</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化 TreeExplainer</span></span><br><span class="line">explainer_raw = shap.TreeExplainer(xgb_model_raw)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算 SHAP 值（基于测试集）</span></span><br><span class="line">shap_values_raw = explainer_raw.shap_values(X_test_raw)</span><br><span class="line"><span class="comment"># SHAP Bar Plot — 显示平均特征影响力</span></span><br><span class="line">shap.summary_plot(shap_values_raw, X_test_raw, plot_type=<span class="string">&#x27;bar&#x27;</span>, show=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># SHAP Dot Plot — 每个样本的分布和特征值颜色</span></span><br><span class="line">shap.summary_plot(shap_values_raw, X_test_raw, plot_type=<span class="string">&#x27;dot&#x27;</span>, show=<span class="literal">True</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p>​<br><img src="/2025/05/04/customer_churn_prediction_model/customer_churn_prediction_model.ipynb_118_0.png" alt="png"><br>​    </p>
<p><img src="/2025/05/04/customer_churn_prediction_model/customer_churn_prediction_model.ipynb_118_1.png" alt="png"></p>
<h3 id="9-2-TOP10"><a href="#9-2-TOP10" class="headerlink" title="9.2 TOP10"></a>9.2 TOP10</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> shap</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化 TreeExplainer</span></span><br><span class="line">explainer_top10 = shap.TreeExplainer(xgb_top10)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算 SHAP 值</span></span><br><span class="line">shap_values_top10 = explainer_top10.shap_values(X_test_top10)</span><br><span class="line"><span class="comment"># 平均影响值排序图</span></span><br><span class="line">shap.summary_plot(shap_values_top10, X_test_top10, plot_type=<span class="string">&#x27;bar&#x27;</span>, show=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 每个样本的 SHAP 分布和特征值颜色</span></span><br><span class="line">shap.summary_plot(shap_values_top10, X_test_top10, plot_type=<span class="string">&#x27;dot&#x27;</span>, show=<span class="literal">True</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p>​<br><img src="/2025/05/04/customer_churn_prediction_model/customer_churn_prediction_model.ipynb_120_0.png" alt="png"><br>​    </p>
<p><img src="/2025/05/04/customer_churn_prediction_model/customer_churn_prediction_model.ipynb_120_1.png" alt="png"></p>
<h3 id="9-3-TOP10-构造特征"><a href="#9-3-TOP10-构造特征" class="headerlink" title="9.3 TOP10 + 构造特征"></a>9.3 TOP10 + 构造特征</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> shap</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化 TreeExplainer（如果还没执行）</span></span><br><span class="line">explainer_constructed = shap.TreeExplainer(xgb_model)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ✅ 计算 SHAP 值（必需）</span></span><br><span class="line">shap_values_constructed = explainer_constructed.shap_values(X_test_enhanced_clean)</span><br><span class="line"><span class="comment"># 条形图</span></span><br><span class="line">shap.summary_plot(shap_values_constructed, X_test_enhanced_clean, plot_type=<span class="string">&#x27;bar&#x27;</span>, show=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分布图</span></span><br><span class="line">shap.summary_plot(shap_values_constructed, X_test_enhanced_clean, plot_type=<span class="string">&#x27;dot&#x27;</span>, show=<span class="literal">True</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p>​<br><img src="/2025/05/04/customer_churn_prediction_model/customer_churn_prediction_model.ipynb_122_0.png" alt="png"><br>​    </p>
<p><img src="/2025/05/04/customer_churn_prediction_model/customer_churn_prediction_model.ipynb_122_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="built_in">list</span>(X_train_sub.columns) == <span class="built_in">list</span>(X_test_sub.columns))</span><br><span class="line"><span class="built_in">print</span>(X_test_sub.columns.difference(X_train_sub.columns))  <span class="comment"># 应该为空</span></span><br><span class="line"><span class="built_in">print</span>(X_train_sub[[<span class="string">&#x27;IsHighValueCustomer&#x27;</span>, <span class="string">&#x27;ServiceCount&#x27;</span>]].describe())</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>True
Index([], dtype=&#39;object&#39;)
       IsHighValueCustomer  ServiceCount
count          5625.000000        5625.0
mean              0.382400           0.0
std               0.486017           0.0
min               0.000000           0.0
25%               0.000000           0.0
50%               0.000000           0.0
75%               1.000000           0.0
max               1.000000           0.0
</code></pre>
<h3 id="🔍-SHAP-分析对比（三组特征版本）"><a href="#🔍-SHAP-分析对比（三组特征版本）" class="headerlink" title="🔍 SHAP 分析对比（三组特征版本）"></a>🔍 SHAP 分析对比（三组特征版本）</h3><h4 id="1-全特征版本"><a href="#1-全特征版本" class="headerlink" title="1. 全特征版本"></a>1. 全特征版本</h4><ul>
<li><strong>主要特征</strong>：<ul>
<li><code>Contract</code>、<code>MonthlyCharges</code>、<code>tenure</code> 是最主要的影响因素。</li>
<li>其次是 <code>TotalCharges</code>、<code>customerID</code>、<code>PaymentMethod</code> 等。</li>
</ul>
</li>
<li><strong>观察到的问题</strong>：<ul>
<li>存在大量冗余特征（如 <code>DeviceProtection</code>, <code>Partner</code>, <code>StreamingMovies</code> 等），对预测几乎无贡献。</li>
<li>模型复杂度较高，存在过拟合风险。</li>
</ul>
</li>
</ul>
<blockquote>
<p>✅ 适合做全面性分析，但不适合部署与泛化。</p>
</blockquote>
<hr>
<h4 id="2-Top10-特征版本（基于-SHAP-排名前十）"><a href="#2-Top10-特征版本（基于-SHAP-排名前十）" class="headerlink" title="2. Top10 特征版本（基于 SHAP 排名前十）"></a>2. Top10 特征版本（基于 SHAP 排名前十）</h4><ul>
<li><strong>特征集中性更强</strong>：<ul>
<li>关键变量仍然是 <code>Contract</code>、<code>MonthlyCharges</code>、<code>tenure</code> 等。</li>
</ul>
</li>
<li><strong>模型结构更简洁</strong>：<ul>
<li>去除冗余特征后，模型解释力更强，性能更稳定。</li>
</ul>
</li>
</ul>
<blockquote>
<p>✅ 推荐作为建模主力方案，易于理解、部署与优化。</p>
</blockquote>
<hr>
<h4 id="3-Top10-构造特征版本"><a href="#3-Top10-构造特征版本" class="headerlink" title="3. Top10 + 构造特征版本"></a>3. Top10 + 构造特征版本</h4><ul>
<li><strong>有效的新特征</strong>：<ul>
<li><code>AvgCharges</code>（总消费 &#x2F; 服务时长）和 <code>Contract_MonthlyInteraction</code> 展示出良好的模型贡献。</li>
</ul>
</li>
<li><strong>低贡献特征</strong>：<ul>
<li><code>ServiceCount</code>、<code>IsHighValueCustomer</code>、<code>TenureGroup_*</code>、<code>TechSupport</code> 等构造特征在本模型中 SHAP 值接近 0，说明它们当前模型中未发挥有效作用。</li>
</ul>
</li>
<li><strong>优势与不足</strong>：<ul>
<li>拓展了模型表达力，但也引入冗余，需要进一步优化。</li>
</ul>
</li>
</ul>
<hr>
<h4 id="后续"><a href="#后续" class="headerlink" title="后续"></a>后续</h4><ol>
<li><strong>精简构造特征</strong>：保留 <code>AvgCharges</code>、<code>Contract_MonthlyInteraction</code> 等有效特征。</li>
<li><strong>进行消融测试（ablation）</strong>：验证每个新特征的正负贡献。</li>
</ol>
<h2 id="10-消融分析"><a href="#10-消融分析" class="headerlink" title="10. 消融分析"></a>10. 消融分析</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score, recall_score, f1_score</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 💡 你已有的列表（用于构建基础 selected_features）</span></span><br><span class="line">top10_features = [</span><br><span class="line">    <span class="string">&#x27;Contract&#x27;</span>, <span class="string">&#x27;tenure&#x27;</span>, <span class="string">&#x27;MonthlyCharges&#x27;</span>, <span class="string">&#x27;TotalCharges&#x27;</span>, <span class="string">&#x27;InternetService&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;OnlineSecurity&#x27;</span>, <span class="string">&#x27;TechSupport&#x27;</span>, <span class="string">&#x27;PaymentMethod&#x27;</span>, <span class="string">&#x27;PaperlessBilling&#x27;</span>, <span class="string">&#x27;SeniorCitizen&#x27;</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 原始构造特征（注意包含 TenureGroup 是逻辑性的）</span></span><br><span class="line">raw_constructed_features = [</span><br><span class="line">    <span class="string">&#x27;AvgCharges&#x27;</span>, <span class="string">&#x27;Contract_MonthlyInteraction&#x27;</span>, <span class="string">&#x27;IsHighValueCustomer&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;ServiceCount&#x27;</span>, <span class="string">&#x27;TenureGroup&#x27;</span>, <span class="string">&#x27;TenureGroup_Mid&#x27;</span>, <span class="string">&#x27;TenureGroup_Long&#x27;</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># ✅ 根据实际列过滤存在的构造特征（重要！）</span></span><br><span class="line">available_cols = X_train_enhanced_clean.columns.tolist()</span><br><span class="line">constructed_features = [f <span class="keyword">for</span> f <span class="keyword">in</span> raw_constructed_features <span class="keyword">if</span> f <span class="keyword">in</span> available_cols]</span><br><span class="line"></span><br><span class="line"><span class="comment"># ✅ 消融分析主循环</span></span><br><span class="line">ablation_results = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> feature_to_drop <span class="keyword">in</span> constructed_features:</span><br><span class="line">    <span class="comment"># 构建特征集（移除该轮要消融的构造特征）</span></span><br><span class="line">    selected_features = top10_features + [f <span class="keyword">for</span> f <span class="keyword">in</span> constructed_features <span class="keyword">if</span> f != feature_to_drop]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        X_train_ablate = X_train_enhanced_clean[selected_features].copy()</span><br><span class="line">        X_test_ablate = X_test_enhanced_clean[selected_features].copy()</span><br><span class="line"></span><br><span class="line">        model = XGBClassifier(use_label_encoder=<span class="literal">False</span>, eval_metric=<span class="string">&#x27;logloss&#x27;</span>, random_state=<span class="number">42</span>)</span><br><span class="line">        model.fit(X_train_ablate, y_train)</span><br><span class="line">        y_pred = model.predict(X_test_ablate)</span><br><span class="line"></span><br><span class="line">        ablation_results.append(&#123;</span><br><span class="line">            <span class="string">&#x27;Dropped_Feature&#x27;</span>: feature_to_drop,</span><br><span class="line">            <span class="string">&#x27;Accuracy&#x27;</span>: accuracy_score(y_test, y_pred),</span><br><span class="line">            <span class="string">&#x27;Recall&#x27;</span>: recall_score(y_test, y_pred),</span><br><span class="line">            <span class="string">&#x27;F1-score&#x27;</span>: f1_score(y_test, y_pred)</span><br><span class="line">        &#125;)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">except</span> KeyError <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;⚠️ 跳过特征 <span class="subst">&#123;feature_to_drop&#125;</span>，因列不存在：<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ✅ 转为表格</span></span><br><span class="line">ablation_df = pd.DataFrame(ablation_results)</span><br><span class="line">ablation_df.sort_values(by=<span class="string">&#x27;F1-score&#x27;</span>, ascending=<span class="literal">False</span>, inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ✅ 显示或保存</span></span><br><span class="line">display(ablation_df)</span><br><span class="line">ablation_df.to_excel(<span class="string">&quot;ablation_results.xlsx&quot;</span>, index=<span class="literal">False</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Dropped_Feature</th>
      <th>Accuracy</th>
      <th>Recall</th>
      <th>F1-score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>4</th>
      <td>TenureGroup_Mid</td>
      <td>0.771855</td>
      <td>0.516043</td>
      <td>0.545969</td>
    </tr>
    <tr>
      <th>3</th>
      <td>ServiceCount</td>
      <td>0.771144</td>
      <td>0.510695</td>
      <td>0.542614</td>
    </tr>
    <tr>
      <th>2</th>
      <td>IsHighValueCustomer</td>
      <td>0.771144</td>
      <td>0.510695</td>
      <td>0.542614</td>
    </tr>
    <tr>
      <th>0</th>
      <td>AvgCharges</td>
      <td>0.769012</td>
      <td>0.508021</td>
      <td>0.539007</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Contract_MonthlyInteraction</td>
      <td>0.769012</td>
      <td>0.505348</td>
      <td>0.537696</td>
    </tr>
  </tbody>
</table>
</div>


<h2 id="11-最终建模"><a href="#11-最终建模" class="headerlink" title="11 最终建模"></a>11 最终建模</h2><h3 id="11-1-建模"><a href="#11-1-建模" class="headerlink" title="11.1 建模"></a>11.1 建模</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"></span><br><span class="line"><span class="comment"># ✅ 定义最终使用的原始 Top10 特征</span></span><br><span class="line">top10_features = [</span><br><span class="line">    <span class="string">&#x27;Contract&#x27;</span>, <span class="string">&#x27;tenure&#x27;</span>, <span class="string">&#x27;MonthlyCharges&#x27;</span>, <span class="string">&#x27;TotalCharges&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;InternetService&#x27;</span>, <span class="string">&#x27;OnlineSecurity&#x27;</span>, <span class="string">&#x27;TechSupport&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;PaymentMethod&#x27;</span>, <span class="string">&#x27;PaperlessBilling&#x27;</span>, <span class="string">&#x27;SeniorCitizen&#x27;</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># ✅ 构造特征中保留的三项（来自消融分析结果）</span></span><br><span class="line">selected_constructed_features = [<span class="string">&#x27;IsHighValueCustomer&#x27;</span>, <span class="string">&#x27;ServiceCount&#x27;</span>, <span class="string">&#x27;TenureGroup&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># ✅ 应用构造函数（你已有定义：add_constructed_features）</span></span><br><span class="line">X_train_enhanced = add_constructed_features(X_train_raw)</span><br><span class="line">X_test_enhanced = add_constructed_features(X_test_raw)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ✅ 提取原始 Top10 + 构造特征列</span></span><br><span class="line">final_raw_features = top10_features + selected_constructed_features</span><br><span class="line">X_train_sub = X_train_enhanced[final_raw_features].copy()</span><br><span class="line">X_test_sub = X_test_enhanced[final_raw_features].copy()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ✅ 对 TenureGroup 进行 One-Hot 编码（仅保留 Mid 一列）</span></span><br><span class="line">encoder = OneHotEncoder(drop=<span class="string">&#x27;first&#x27;</span>, sparse_output=<span class="literal">False</span>, handle_unknown=<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line">encoded_train = encoder.fit_transform(X_train_sub[[<span class="string">&#x27;TenureGroup&#x27;</span>]])</span><br><span class="line">encoded_test = encoder.transform(X_test_sub[[<span class="string">&#x27;TenureGroup&#x27;</span>]])</span><br><span class="line">encoded_cols = encoder.get_feature_names_out([<span class="string">&#x27;TenureGroup&#x27;</span>])  <span class="comment"># eg. [&#x27;TenureGroup_Mid&#x27;]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ✅ 拼接编码结果并删除原列</span></span><br><span class="line">X_train_encoded = pd.DataFrame(encoded_train, columns=encoded_cols, index=X_train_sub.index)</span><br><span class="line">X_test_encoded = pd.DataFrame(encoded_test, columns=encoded_cols, index=X_test_sub.index)</span><br><span class="line"></span><br><span class="line">X_train_final = pd.concat([X_train_sub.drop(columns=[<span class="string">&#x27;TenureGroup&#x27;</span>]), X_train_encoded], axis=<span class="number">1</span>)</span><br><span class="line">X_test_final = pd.concat([X_test_sub.drop(columns=[<span class="string">&#x27;TenureGroup&#x27;</span>]), X_test_encoded], axis=<span class="number">1</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score, precision_score, recall_score, f1_score</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># ✅ 仅对数值列进行标准化（适用于 Logistic Regression）</span></span><br><span class="line">numeric_cols = [<span class="string">&#x27;tenure&#x27;</span>, <span class="string">&#x27;MonthlyCharges&#x27;</span>, <span class="string">&#x27;TotalCharges&#x27;</span>, <span class="string">&#x27;ServiceCount&#x27;</span>]</span><br><span class="line"></span><br><span class="line">scaler_final = StandardScaler()</span><br><span class="line">X_train_log_final = X_train_final.copy()</span><br><span class="line">X_test_log_final = X_test_final.copy()</span><br><span class="line"></span><br><span class="line">X_train_log_final[numeric_cols] = scaler_final.fit_transform(X_train_log_final[numeric_cols])</span><br><span class="line">X_test_log_final[numeric_cols] = scaler_final.transform(X_test_log_final[numeric_cols])</span><br><span class="line"></span><br><span class="line"><span class="comment"># ✅ 训练模型</span></span><br><span class="line">log_final_model = LogisticRegression(class_weight=<span class="string">&#x27;balanced&#x27;</span>, max_iter=<span class="number">1000</span>, random_state=<span class="number">42</span>)</span><br><span class="line">log_final_model.fit(X_train_log_final, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ✅ 预测</span></span><br><span class="line">y_pred_log_final = log_final_model.predict(X_test_log_final)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ✅ 指标汇总</span></span><br><span class="line">log_final_metrics = &#123;</span><br><span class="line">    <span class="string">&#x27;Model&#x27;</span>: <span class="string">&#x27;Logistic Regression (Final)&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Accuracy&#x27;</span>: accuracy_score(y_test, y_pred_log_final),</span><br><span class="line">    <span class="string">&#x27;Precision&#x27;</span>: precision_score(y_test, y_pred_log_final),</span><br><span class="line">    <span class="string">&#x27;Recall&#x27;</span>: recall_score(y_test, y_pred_log_final),</span><br><span class="line">    <span class="string">&#x27;F1-score&#x27;</span>: f1_score(y_test, y_pred_log_final)</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score, precision_score, recall_score, f1_score</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># ✅ 训练模型（无需标准化）</span></span><br><span class="line">rf_final_model = RandomForestClassifier(class_weight=<span class="string">&#x27;balanced&#x27;</span>, n_estimators=<span class="number">100</span>, random_state=<span class="number">42</span>)</span><br><span class="line">rf_final_model.fit(X_train_final, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ✅ 预测</span></span><br><span class="line">y_pred_rf_final = rf_final_model.predict(X_test_final)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ✅ 指标汇总</span></span><br><span class="line">rf_final_metrics = &#123;</span><br><span class="line">    <span class="string">&#x27;Model&#x27;</span>: <span class="string">&#x27;Random Forest (Final)&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Accuracy&#x27;</span>: accuracy_score(y_test, y_pred_rf_final),</span><br><span class="line">    <span class="string">&#x27;Precision&#x27;</span>: precision_score(y_test, y_pred_rf_final),</span><br><span class="line">    <span class="string">&#x27;Recall&#x27;</span>: recall_score(y_test, y_pred_rf_final),</span><br><span class="line">    <span class="string">&#x27;F1-score&#x27;</span>: f1_score(y_test, y_pred_rf_final)</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score, precision_score, recall_score, f1_score</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># ✅ 训练模型（无需标准化）</span></span><br><span class="line">xgb_final_model = XGBClassifier(use_label_encoder=<span class="literal">False</span>, eval_metric=<span class="string">&#x27;logloss&#x27;</span>, random_state=<span class="number">42</span>)</span><br><span class="line">xgb_final_model.fit(X_train_final, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ✅ 预测</span></span><br><span class="line">y_pred_xgb_final = xgb_final_model.predict(X_test_final)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ✅ 指标汇总</span></span><br><span class="line">xgb_final_metrics = &#123;</span><br><span class="line">    <span class="string">&#x27;Model&#x27;</span>: <span class="string">&#x27;XGBoost (Final)&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;Accuracy&#x27;</span>: accuracy_score(y_test, y_pred_xgb_final),</span><br><span class="line">    <span class="string">&#x27;Precision&#x27;</span>: precision_score(y_test, y_pred_xgb_final),</span><br><span class="line">    <span class="string">&#x27;Recall&#x27;</span>: recall_score(y_test, y_pred_xgb_final),</span><br><span class="line">    <span class="string">&#x27;F1-score&#x27;</span>: f1_score(y_test, y_pred_xgb_final)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="11-2-评估"><a href="#11-2-评估" class="headerlink" title="11.2 评估"></a>11.2 评估</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 确保你已经运行过以下三个变量：</span></span><br><span class="line"><span class="comment"># log_final_metrics, rf_final_metrics, xgb_final_metrics</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 汇总成 DataFrame</span></span><br><span class="line">final_results_df = pd.DataFrame([</span><br><span class="line">    log_final_metrics,</span><br><span class="line">    rf_final_metrics,</span><br><span class="line">    xgb_final_metrics</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">display(final_results_df)</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Model</th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1-score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Logistic Regression (Final)</td>
      <td>0.718550</td>
      <td>0.482484</td>
      <td>0.810160</td>
      <td>0.604790</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Random Forest (Final)</td>
      <td>0.778962</td>
      <td>0.603960</td>
      <td>0.489305</td>
      <td>0.540620</td>
    </tr>
    <tr>
      <th>2</th>
      <td>XGBoost (Final)</td>
      <td>0.776830</td>
      <td>0.590361</td>
      <td>0.524064</td>
      <td>0.555241</td>
    </tr>
  </tbody>
</table>
</div>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> shap</span><br><span class="line"></span><br><span class="line"><span class="comment"># ✅ 初始化 explainer</span></span><br><span class="line">explainer_final = shap.Explainer(xgb_final_model)</span><br><span class="line">shap_values_final = explainer_final(X_test_final)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ✅ 1️⃣ 特征重要性条形图（全局）</span></span><br><span class="line">shap.plots.bar(shap_values_final, max_display=<span class="number">15</span>, show=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ✅ 2️⃣ SHAP 分布图（每个样本 × 每个特征，颜色代表特征值高低）</span></span><br><span class="line">shap.plots.beeswarm(shap_values_final, max_display=<span class="number">15</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p>​<br><img src="/2025/05/04/customer_churn_prediction_model/customer_churn_prediction_model.ipynb_136_0.png" alt="png"><br>​    </p>
<p><img src="/2025/05/04/customer_churn_prediction_model/customer_churn_prediction_model.ipynb_136_1.png" alt="png"></p>
<h4 id="最终建模"><a href="#最终建模" class="headerlink" title="最终建模"></a>最终建模</h4><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Model</th>
      <th>Accuracy</th>
      <th>Precision</th>
      <th>Recall</th>
      <th>F1-score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Logistic Regression (Final)</td>
      <td>0.718550</td>
      <td>0.482484</td>
      <td>0.810160</td>
      <td>0.604790</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Random Forest (Final)</td>
      <td>0.778962</td>
      <td>0.603960</td>
      <td>0.489305</td>
      <td>0.540620</td>
    </tr>
    <tr>
      <th>2</th>
      <td>XGBoost (Final)</td>
      <td>0.776830</td>
      <td>0.590361</td>
      <td>0.524064</td>
      <td>0.555241</td>
    </tr>
  </tbody>
</table>
</div>

<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="http://example.com">Jin</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="http://example.com/2025/05/04/customer_churn_prediction_model.ipynb/">http://example.com/2025/05/04/customer_churn_prediction_model.ipynb/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles on this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless otherwise stated.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Python/">Python</a><a class="post-meta__tags" href="/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/">数据分析</a></div><div class="post-share"><div class="social-share" data-image="/img/avatar.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related full-width" href="/2025/03/30/House_predict/" title="房价预测项目总结"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">Previous</div><div class="info-item-2">房价预测项目总结</div></div><div class="info-2"><div class="info-item-1">导包 描述性统计 查看缺失值1!where python  # Windows  12345import pandas as pdtrain = pd.read_csv(&#x27;train.csv&#x27;)test = pd.read_csv(&#x27;test.csv&#x27;)   123456789# 查看数据形状print(&quot;Train shape:&quot;, train.shape)print(&quot;Test shape:&quot;, test.shape)# 查看前5行train.head()# 查看数据概况train.info()  Train shape: (1460, 81) Test shape: (1459, 80) &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 1460 entries, 0 to 1459 Data columns (total 81 columns):  #   Column         Non-Null Count...</div></div></div></a></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/avatar.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Jin</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">3</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">3</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">4</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Jin-123-321"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">欢迎来到 Jin 的机器学习旅途博客 ✨<br>用代码探索世界，以图表理解数据！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Telco-Customer-Churn-Prediction"><span class="toc-number">1.</span> <span class="toc-text">Telco Customer Churn Prediction</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D-%E7%9B%AE%E6%A0%87%E8%AF%B4%E6%98%8E"><span class="toc-number">1.1.</span> <span class="toc-text">1. 项目介绍 &amp; 目标说明</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E5%AF%BC%E5%85%A5%E5%BA%93-%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE"><span class="toc-number">1.2.</span> <span class="toc-text">2. 导入库 &amp; 加载数据</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E6%9F%A5%E7%9C%8B%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="toc-number">1.2.1.</span> <span class="toc-text">2.1. 查看数据结构和数据类型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%F0%9F%A7%BC-%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97%E9%87%8D%E7%82%B9%E6%80%BB%E7%BB%93"><span class="toc-number">1.2.1.1.</span> <span class="toc-text">🧼 数据清洗重点总结</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E2%9C%85-%E6%B8%85%E6%B4%97%E5%AE%8C%E6%88%90%E5%90%8E%E7%9A%84%E7%9B%AE%E6%A0%87%EF%BC%9A"><span class="toc-number">1.2.1.1.1.</span> <span class="toc-text">✅ 清洗完成后的目标：</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97%E4%B8%8E%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">1.3.</span> <span class="toc-text">3. 数据清洗与预处理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-%E7%BC%BA%E5%A4%B1%E5%80%BC%E5%A4%84%E7%90%86"><span class="toc-number">1.3.1.</span> <span class="toc-text">3.1 缺失值处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-%E7%89%B9%E5%BE%81%E7%BC%96%E7%A0%81"><span class="toc-number">1.3.2.</span> <span class="toc-text">3.2 特征编码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-%E7%89%B9%E5%BE%81%E7%BC%A9%E6%94%BE"><span class="toc-number">1.3.3.</span> <span class="toc-text">3.3 特征缩放</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E6%8E%A2%E7%B4%A2%E6%80%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%EF%BC%88EDA%EF%BC%89"><span class="toc-number">1.4.</span> <span class="toc-text">4. 探索性数据分析（EDA）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-%E7%9B%AE%E6%A0%87%E5%8F%98%E9%87%8F%E5%88%86%E5%B8%83%EF%BC%88Churn-%E6%A6%82%E5%86%B5%EF%BC%89"><span class="toc-number">1.4.1.</span> <span class="toc-text">4.1 目标变量分布（Churn 概况）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E2%9A%96%EF%B8%8F-%E7%B1%BB%E5%88%AB%E4%B8%8D%E5%B9%B3%E8%A1%A1%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95%E8%AF%B4%E6%98%8E"><span class="toc-number">1.4.1.1.</span> <span class="toc-text">⚖️ 类别不平衡处理方法说明</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-%F0%9F%91%A8%E2%80%8D%F0%9F%91%A9%E2%80%8D%F0%9F%91%A7-%E7%B1%BB%E5%88%AB%E5%8F%98%E9%87%8F-vs-%E6%B5%81%E5%A4%B1%E7%8E%87%EF%BC%88%E5%8D%95%E5%8F%98%E9%87%8F%E5%88%86%E6%9E%90%EF%BC%89"><span class="toc-number">1.4.2.</span> <span class="toc-text">4.2 👨‍👩‍👧 类别变量 vs. 流失率（单变量分析）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-%F0%9F%93%89-%E6%95%B0%E5%80%BC%E5%8F%98%E9%87%8F%E5%9C%A8%E4%B8%8D%E5%90%8C%E6%B5%81%E5%A4%B1%E7%8A%B6%E6%80%81%E4%B8%8B%E7%9A%84%E5%88%86%E5%B8%83%EF%BC%88%E7%AE%B1%E7%BA%BF%E5%9B%BE%E5%88%86%E6%9E%90%EF%BC%89"><span class="toc-number">1.4.3.</span> <span class="toc-text">4.3 📉 数值变量在不同流失状态下的分布（箱线图分析）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E2%9C%85-tenure%EF%BC%88%E5%9C%A8%E7%BD%91%E6%97%B6%E9%95%BF%EF%BC%89"><span class="toc-number">1.4.3.0.1.</span> <span class="toc-text">✅ tenure（在网时长）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E2%9C%85-MonthlyCharges%EF%BC%88%E6%9C%88%E5%BA%A6%E6%94%B6%E8%B4%B9%EF%BC%89"><span class="toc-number">1.4.3.0.2.</span> <span class="toc-text">✅ MonthlyCharges（月度收费）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E2%9C%85-TotalCharges%EF%BC%88%E6%80%BB%E8%B4%B9%E7%94%A8%EF%BC%89"><span class="toc-number">1.4.3.0.3.</span> <span class="toc-text">✅ TotalCharges（总费用）</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%F0%9F%94%8D-%E5%B0%8F%E7%BB%93%E5%BB%BA%E8%AE%AE"><span class="toc-number">1.4.3.1.</span> <span class="toc-text">🔍 小结建议</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-4-%F0%9F%94%A5-%E7%89%B9%E5%BE%81%E7%9B%B8%E5%85%B3%E6%80%A7%E7%83%AD%E5%8A%9B%E5%9B%BE"><span class="toc-number">1.4.4.</span> <span class="toc-text">4.4 🔥 特征相关性热力图</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E2%9C%85-%E4%B8%8E%E7%9B%AE%E6%A0%87%E5%8F%98%E9%87%8F-Churn-%E7%9A%84%E7%9B%B8%E5%85%B3%E6%80%A7"><span class="toc-number">1.4.4.0.1.</span> <span class="toc-text">✅ 与目标变量 Churn 的相关性</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E2%9A%A0%EF%B8%8F-%E7%89%B9%E5%BE%81%E4%B9%8B%E9%97%B4%E7%9A%84%E5%BC%BA%E7%9B%B8%E5%85%B3%E6%80%A7%EF%BC%88%E6%BD%9C%E5%9C%A8%E5%86%97%E4%BD%99%EF%BC%89"><span class="toc-number">1.4.4.0.2.</span> <span class="toc-text">⚠️ 特征之间的强相关性（潜在冗余）</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E2%9C%85-%E5%BB%BA%E8%AE%AE%EF%BC%88%E4%B8%BA%E5%90%8E%E7%BB%AD%E5%BB%BA%E6%A8%A1%E5%81%9A%E5%87%86%E5%A4%87%EF%BC%89"><span class="toc-number">1.4.4.1.</span> <span class="toc-text">✅ 建议（为后续建模做准备）</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-5-%F0%9F%8E%AF-%E6%95%B0%E5%80%BC%E5%8F%98%E9%87%8F%E5%88%86%E5%B8%83%E5%9B%BE%EF%BC%88%E6%8C%89%E6%B5%81%E5%A4%B1%E6%83%85%E5%86%B5%E5%88%86%E7%BB%84%EF%BC%89"><span class="toc-number">1.4.5.</span> <span class="toc-text">4.5 🎯 数值变量分布图（按流失情况分组）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1%EF%B8%8F%E2%83%A3-tenure%EF%BC%88%E5%9C%A8%E7%BD%91%E6%97%B6%E9%95%BF%EF%BC%89"><span class="toc-number">1.4.5.0.1.</span> <span class="toc-text">1️⃣ tenure（在网时长）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2%EF%B8%8F%E2%83%A3-MonthlyCharges%EF%BC%88%E6%9C%88%E5%BA%A6%E6%B6%88%E8%B4%B9%EF%BC%89"><span class="toc-number">1.4.5.0.2.</span> <span class="toc-text">2️⃣ MonthlyCharges（月度消费）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3%EF%B8%8F%E2%83%A3-TotalCharges%EF%BC%88%E6%80%BB%E6%B6%88%E8%B4%B9%E9%87%91%E9%A2%9D%EF%BC%89"><span class="toc-number">1.4.5.0.3.</span> <span class="toc-text">3️⃣ TotalCharges（总消费金额）</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E2%9C%85-%E7%BB%BC%E5%90%88%E7%BB%93%E8%AE%BA"><span class="toc-number">1.4.5.1.</span> <span class="toc-text">✅ 综合结论</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-6-%F0%9F%94%8D-%E9%AB%98%E9%98%B6%E7%BB%84%E5%90%88%E7%89%B9%E5%BE%81%E4%BA%A4%E5%8F%89%E5%88%86%E6%9E%90"><span class="toc-number">1.4.6.</span> <span class="toc-text">4.6 🔍 高阶组合特征交叉分析</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1%EF%B8%8F%E2%83%A3-Contract-PaymentMethod-%E5%AF%B9%E6%B5%81%E5%A4%B1%E7%8E%87%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="toc-number">1.4.6.1.</span> <span class="toc-text">1️⃣ Contract + PaymentMethod 对流失率的影响</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2%EF%B8%8F%E2%83%A3-InternetService-OnlineSecurity-%E7%BB%84%E5%90%88%E5%88%86%E6%9E%90"><span class="toc-number">1.4.6.2.</span> <span class="toc-text">2️⃣ InternetService + OnlineSecurity 组合分析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3%EF%B8%8F%E2%83%A3-MonthlyCharges-tenure%EF%BC%88%E5%88%86%E7%AE%B1%EF%BC%89-%E7%BB%84%E5%90%88%E5%88%86%E6%9E%90"><span class="toc-number">1.4.6.3.</span> <span class="toc-text">3️⃣ MonthlyCharges + tenure（分箱） 组合分析</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E5%BB%BA%E6%A8%A1%E4%B8%8E%E8%AF%84%E4%BC%B0"><span class="toc-number">1.5.</span> <span class="toc-text">5. 建模与评估</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-%E5%BB%BA%E6%A8%A1"><span class="toc-number">1.5.1.</span> <span class="toc-text">5.1 建模</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#5-1-1%EF%BC%9ALogistic-Regression"><span class="toc-number">1.5.1.1.</span> <span class="toc-text">5.1.1：Logistic Regression</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-1-2%EF%BC%9ASVM"><span class="toc-number">1.5.1.2.</span> <span class="toc-text">5.1.2：SVM</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-1-3%EF%BC%9AKNN"><span class="toc-number">1.5.1.3.</span> <span class="toc-text">5.1.3：KNN</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-1-4%EF%BC%9ARandom-Forest"><span class="toc-number">1.5.1.4.</span> <span class="toc-text">5.1.4：Random Forest</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-1-5%EF%BC%9AXGBoost"><span class="toc-number">1.5.1.5.</span> <span class="toc-text">5.1.5：XGBoost</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-1-6%EF%BC%9ANeural-Network%EF%BC%88MLP%EF%BC%89"><span class="toc-number">1.5.1.6.</span> <span class="toc-text">5.1.6：Neural Network（MLP）</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87%EF%BC%88Accuracy%E3%80%81Recall%E3%80%81F1%E3%80%81ROC%EF%BC%89"><span class="toc-number">1.5.2.</span> <span class="toc-text">5.2 评估指标（Accuracy、Recall、F1、ROC）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E7%BB%93%E6%9E%9C%E5%88%86%E6%9E%90%EF%BC%88%E5%88%9D%E6%AD%A5%EF%BC%89"><span class="toc-number">1.5.2.1.</span> <span class="toc-text">模型评估结果分析（初步）</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-%E6%A8%A1%E5%9E%8B%E8%A7%A3%E9%87%8A"><span class="toc-number">1.6.</span> <span class="toc-text">6. 模型解释</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#6-1-%E6%8F%90%E5%8F%96%E7%89%B9%E5%BE%81%E9%87%8D%E8%A6%81%E6%80%A7%E6%8E%92%E5%90%8D%EF%BC%88%E6%9F%B1%E7%8A%B6%E5%9B%BE"><span class="toc-number">1.6.1.</span> <span class="toc-text">6.1 提取特征重要性排名（柱状图)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-2-XGBoost-%E5%86%85%E7%BD%AE%E7%89%B9%E5%BE%81%E9%87%8D%E8%A6%81%E6%80%A7%EF%BC%88Gain%EF%BC%89"><span class="toc-number">1.6.2.</span> <span class="toc-text">6.2 XGBoost 内置特征重要性（Gain）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-%E9%87%8D%E5%BB%BA%E6%A8%A1%E5%9E%8B-%E7%89%B9%E5%BE%81%E9%80%89%E5%8F%96-%E6%9E%84%E9%80%A0"><span class="toc-number">1.7.</span> <span class="toc-text">7. 重建模型 特征选取&#x2F;构造</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#7-1-%E9%80%89%E5%8F%96%E9%87%8D%E8%A6%81%E7%89%B9%E5%BE%81%E9%87%8D%E5%BB%BA%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.7.1.</span> <span class="toc-text">7.1 选取重要特征重建模型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#7-1-1-Logistic-Regression"><span class="toc-number">1.7.1.1.</span> <span class="toc-text">7.1.1 Logistic Regression</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#7-1-2-Random-Forest"><span class="toc-number">1.7.1.2.</span> <span class="toc-text">7.1.2 Random Forest</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#7-1-3-XGBoost"><span class="toc-number">1.7.1.3.</span> <span class="toc-text">7.1.3 XGBoost</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#7-1-4-%E6%89%93%E5%8C%85%E8%BE%93%E5%87%BA"><span class="toc-number">1.7.1.4.</span> <span class="toc-text">7.1.4 打包输出</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-2-%E7%89%B9%E5%BE%81%E6%9E%84%E9%80%A0"><span class="toc-number">1.7.2.</span> <span class="toc-text">7.2 特征构造</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#7-3-1-%E6%9E%84%E9%80%A0%E5%A2%9E%E5%BC%BA%E7%89%B9%E5%BE%81%E5%87%BD%E6%95%B0"><span class="toc-number">1.7.2.1.</span> <span class="toc-text">7.3.1 构造增强特征函数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#7-3-2-%E7%89%B9%E5%BE%81%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">1.7.2.2.</span> <span class="toc-text">7.3.2 特征预处理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#7-4-1-Logistic-Regression%EF%BC%88%E5%9F%BA%E4%BA%8ETOP10-%E5%A2%9E%E5%BC%BA%E7%89%B9%E5%BE%81%EF%BC%89"><span class="toc-number">1.7.2.3.</span> <span class="toc-text">7.4.1 Logistic Regression（基于TOP10 + 增强特征）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#7-4-2-Random-Forest%EF%BC%88%E5%9F%BA%E4%BA%8E-Top10-%E6%9E%84%E9%80%A0%E7%89%B9%E5%BE%81%EF%BC%89"><span class="toc-number">1.7.2.4.</span> <span class="toc-text">7.4.2 Random Forest（基于 Top10 + 构造特征）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#7-4-3-XGBoost%EF%BC%88%E5%9F%BA%E4%BA%8E-Top10-%E6%9E%84%E9%80%A0%E7%89%B9%E5%BE%81%EF%BC%89"><span class="toc-number">1.7.2.5.</span> <span class="toc-text">7.4.3 XGBoost（基于 Top10 + 构造特征）</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-4-%E6%B1%87%E6%80%BB"><span class="toc-number">1.7.3.</span> <span class="toc-text">7.4 汇总</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-%E4%B8%8D%E5%90%8C%E7%89%B9%E5%BE%81%E9%80%89%E5%8F%96-%E5%BB%BA%E6%A8%A1%E7%BB%93%E6%9E%9C%E5%AF%B9%E6%AF%94"><span class="toc-number">1.8.</span> <span class="toc-text">8. 不同特征选取 建模结果对比</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%A8%E7%89%B9%E5%BE%81"><span class="toc-number">1.8.0.1.</span> <span class="toc-text">全特征</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#TOP10"><span class="toc-number">1.8.0.2.</span> <span class="toc-text">TOP10</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#TOP10-%E6%9E%84%E9%80%A0%E7%89%B9%E5%BE%81"><span class="toc-number">1.8.0.3.</span> <span class="toc-text">TOP10 + 构造特征</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-SHAP-%E5%88%86%E6%9E%90%EF%BC%88%E5%9F%BA%E4%BA%8EXGBoost-%E9%80%89%E5%8F%96%E4%B8%8D%E5%90%8C%E7%89%B9%E5%BE%81%E8%BF%9B%E8%A1%8C%EF%BC%89"><span class="toc-number">1.9.</span> <span class="toc-text">9. SHAP 分析（基于XGBoost 选取不同特征进行）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#9-1-%E5%85%A8%E7%89%B9%E5%BE%81"><span class="toc-number">1.9.1.</span> <span class="toc-text">9.1 全特征</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-2-TOP10"><span class="toc-number">1.9.2.</span> <span class="toc-text">9.2 TOP10</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-3-TOP10-%E6%9E%84%E9%80%A0%E7%89%B9%E5%BE%81"><span class="toc-number">1.9.3.</span> <span class="toc-text">9.3 TOP10 + 构造特征</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%F0%9F%94%8D-SHAP-%E5%88%86%E6%9E%90%E5%AF%B9%E6%AF%94%EF%BC%88%E4%B8%89%E7%BB%84%E7%89%B9%E5%BE%81%E7%89%88%E6%9C%AC%EF%BC%89"><span class="toc-number">1.9.4.</span> <span class="toc-text">🔍 SHAP 分析对比（三组特征版本）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E5%85%A8%E7%89%B9%E5%BE%81%E7%89%88%E6%9C%AC"><span class="toc-number">1.9.4.1.</span> <span class="toc-text">1. 全特征版本</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-Top10-%E7%89%B9%E5%BE%81%E7%89%88%E6%9C%AC%EF%BC%88%E5%9F%BA%E4%BA%8E-SHAP-%E6%8E%92%E5%90%8D%E5%89%8D%E5%8D%81%EF%BC%89"><span class="toc-number">1.9.4.2.</span> <span class="toc-text">2. Top10 特征版本（基于 SHAP 排名前十）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-Top10-%E6%9E%84%E9%80%A0%E7%89%B9%E5%BE%81%E7%89%88%E6%9C%AC"><span class="toc-number">1.9.4.3.</span> <span class="toc-text">3. Top10 + 构造特征版本</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%90%8E%E7%BB%AD"><span class="toc-number">1.9.4.4.</span> <span class="toc-text">后续</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-%E6%B6%88%E8%9E%8D%E5%88%86%E6%9E%90"><span class="toc-number">1.10.</span> <span class="toc-text">10. 消融分析</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#11-%E6%9C%80%E7%BB%88%E5%BB%BA%E6%A8%A1"><span class="toc-number">1.11.</span> <span class="toc-text">11 最终建模</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#11-1-%E5%BB%BA%E6%A8%A1"><span class="toc-number">1.11.1.</span> <span class="toc-text">11.1 建模</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-2-%E8%AF%84%E4%BC%B0"><span class="toc-number">1.11.2.</span> <span class="toc-text">11.2 评估</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%80%E7%BB%88%E5%BB%BA%E6%A8%A1"><span class="toc-number">1.11.2.1.</span> <span class="toc-text">最终建模</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">1.12.</span> <span class="toc-text">总结</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Posts</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/05/04/customer_churn_prediction_model.ipynb/" title="Customer Churn Prediction Model">Customer Churn Prediction Model</a><time datetime="2025-05-04T13:00:00.000Z" title="Created 2025-05-04 21:00:00">2025-05-04</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/03/30/House_predict/" title="房价预测项目总结">房价预测项目总结</a><time datetime="2025-03-29T16:00:00.000Z" title="Created 2025-03-30 00:00:00">2025-03-30</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/03/28/titanic_analysis/" title="泰坦尼克号项目总结">泰坦尼克号项目总结</a><time datetime="2025-03-27T16:00:00.000Z" title="Created 2025-03-28 00:00:00">2025-03-28</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2025 By Jin</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.3.5</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Reading Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light and Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle Between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Settings"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back to Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>